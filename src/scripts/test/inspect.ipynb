{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set configs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3,4][0:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inspect the overlapping neuron indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "AutoTokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfixed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\"fixed\".split(\"_\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  col1 col2  value\n",
      "0    A    X   15.0\n",
      "1    A    Y   30.0\n",
      "2    B    X   40.0\n",
      "3    B    Y   55.0\n"
     ]
    }
   ],
   "source": [
    "result = df.groupby(['col1', 'col2'])['value'].mean().reset_index()\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'col1': {0: 'A', 1: 'A', 2: 'B', 3: 'B'}, 'col2': {0: 'X', 1: 'Y', 2: 'X', 3: 'Y'}, 'value': {0: 15.0, 1: 30.0, 2: 40.0, 3: 55.0}}\n"
     ]
    }
   ],
   "source": [
    "result = df.groupby(['col1', 'col2'])['value'].mean().reset_index().to_dict()\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.2_activation\n"
     ]
    }
   ],
   "source": [
    "def _filter_token(self, fea_data, groupby_col: str, sort_by_col: str) -> pd.DataFrame:\n",
    "        \"\"\"Filter top-n tokens together with the rows.\"\"\"\n",
    "        first_n_groups = fea_data[groupby_col].drop_duplicates().head(self.args.fea_dim)\n",
    "        filtered_df = fea_data[fea_data[groupby_col].isin(first_n_groups)]\n",
    "        if \"longtail\" in self.args.sel_freq:\n",
    "            return (\n",
    "                filtered_df.sort_values(by=sort_by_col, ascending=True).groupby(groupby_col, group_keys=False).head(1)\n",
    "            )\n",
    "        return filtered_df.sort_values(by=sort_by_col, ascending=False).groupby(groupby_col, group_keys=False).head(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    token  score other_info\n",
      "0   apple   0.90         a1\n",
      "1   apple   0.50         a2\n",
      "2  banana   0.70         b1\n",
      "3  banana   0.20         b2\n",
      "4  cherry   0.95         c1\n",
      "5  cherry   0.85         c2\n",
      "6    date   0.10         d1\n",
      "7    date   0.40         d2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'token': ['apple', 'apple', 'banana', 'banana', 'cherry', 'cherry', 'date', 'date'],\n",
    "    'score': [0.9, 0.5, 0.7, 0.2, 0.95, 0.85, 0.1, 0.4],\n",
    "    'other_info': ['a1', 'a2', 'b1', 'b2', 'c1', 'c2', 'd1', 'd2']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _filter_token(fea_data, groupby_col: str, sort_by_col: str) -> pd.DataFrame:\n",
    "    fea_data = fea_data.sort_values(by=sort_by_col, ascending=True)\n",
    "    fea_data = fea_data.drop_duplicates(groupby_col)\n",
    "    return fea_data.sort_values(by=sort_by_col, ascending=True).head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>score</th>\n",
       "      <th>other_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>date</td>\n",
       "      <td>0.1</td>\n",
       "      <td>d1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>banana</td>\n",
       "      <td>0.2</td>\n",
       "      <td>b2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apple</td>\n",
       "      <td>0.5</td>\n",
       "      <td>a2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    token  score other_info\n",
       "6    date    0.1         d1\n",
       "3  banana    0.2         b2\n",
       "1   apple    0.5         a2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fea_data = df\n",
    "_filter_token(fea_data, \"token\", \"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'b': 2, 'c': 3}\n"
     ]
    }
   ],
   "source": [
    "# Input dictionary\n",
    "my_dict = {'b': 2, 'a': 1, 'c': 3}\n",
    "\n",
    "# Desired key order\n",
    "key_order = ['a', 'b', 'c']\n",
    "\n",
    "# Sort dictionary to match the key order\n",
    "sorted_dict = {k: my_dict[k] for k in key_order if k in my_dict}\n",
    "\n",
    "print(sorted_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = fea_data[fea_data[groupby_col].isin(first_n_groups)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 6]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lst =[1,2,3,4,4,5,6][2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n"
     ]
    }
   ],
   "source": [
    "positions = [\"a\",\"b\"]\n",
    "\n",
    "for pos_idx, pos in enumerate(positions):\n",
    "    print(pos)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_idx(neuron_path,vec,model,neuron_num):\n",
    "    \"\"\"Compare whether the 2 index lists are the same.\"\"\"\n",
    "    boost_df = pd.read_csv(neuron_path/\"boost\"/vec/\"EleutherAI\"/f\"pythia-{model}-deduped\"/f\"500_{neuron_num}.csv\")\n",
    "    suppress_df = pd.read_csv(neuron_path/\"suppress\"/vec/\"EleutherAI\"/f\"pythia-{model}-deduped\"/f\"500_{neuron_num}.csv\")\n",
    "    boost_idx = set(ast.literal_eval(boost_df[\"top_neurons\"].to_list()))\n",
    "    suppress_idx = set(ast.literal_eval(suppress_df[\"top_neurons\"].to_list()))\n",
    "    common_idx = boost_idx & suppress_idx\n",
    "    return True if len(common_idx) > 0 else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_idx(neuron_path, vec, model, neuron_num):\n",
    "    \"\"\" Compare whether neuron indices overlap between boost and suppress conditions.\"\"\"\n",
    "    try:\n",
    "        # Construct file paths\n",
    "        boost_file = neuron_path / \"boost\" / vec / \"EleutherAI\" / f\"pythia-{model}-deduped\" / f\"500_{neuron_num}.csv\"\n",
    "        suppress_file = neuron_path / \"suppress\" / vec / \"EleutherAI\" / f\"pythia-{model}-deduped\" / f\"500_{neuron_num}.csv\"\n",
    "        # Check if files exist\n",
    "        if not boost_file.exists() or not suppress_file.exists():\n",
    "            print(f\"Warning: One or both files do not exist: {boost_file}, {suppress_file}\")\n",
    "            return False\n",
    "        # Read CSV files\n",
    "        boost_df = pd.read_csv(boost_file)\n",
    "        suppress_df = pd.read_csv(suppress_file)\n",
    " \n",
    "        # loop over different steps\n",
    "        n = 0\n",
    "        while n < boost_df.shape[0]:\n",
    "            boost_neurons = set(ast.literal_eval(boost_df[\"top_neurons\"].tolist()[n]))\n",
    "            suppress_neurons = set(ast.literal_eval(suppress_df[\"top_neurons\"].tolist()[n]))\n",
    "            if len(boost_neurons & suppress_neurons) > 0:\n",
    "                #print(suppress_df[\"top_neurons\"].tolist()[n])\n",
    "                print(suppress_df[\"step\"].tolist()[n])\n",
    "                print((boost_neurons & suppress_neurons))\n",
    "                \n",
    "            n += 1\n",
    "    except Exception as e:\n",
    "        print(f\"Error in compare_idx: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90000\n",
      "{'5.311', '5.986', '5.404'}\n",
      "0\n",
      "{'5.884', '5.281', '5.381'}\n",
      "40000\n",
      "{'5.1622', '5.311', '5.1212', '5.213'}\n",
      "1\n",
      "{'5.381', '5.1661', '5.1681', '5.544', '5.1258'}\n",
      "91000\n",
      "{'5.302'}\n",
      "41000\n",
      "{'5.1622', '5.311', '5.1631', '5.213'}\n",
      "2\n",
      "{'5.884', '5.1661', '5.1202', '5.553', '5.1957'}\n",
      "92000\n",
      "{'5.311', '5.638', '5.1571', '5.404'}\n",
      "42000\n",
      "{'5.1622', '5.311'}\n",
      "4\n",
      "{'5.544', '5.1258', '5.553', '5.1007'}\n",
      "93000\n",
      "{'5.251', '5.638'}\n",
      "43000\n",
      "{'5.367', '5.1622', '5.213', '5.311', '5.1631'}\n",
      "8\n",
      "{'5.544', '5.884', '5.1202', '5.770'}\n",
      "94000\n",
      "{'5.1571', '5.404'}\n",
      "44000\n",
      "{'5.1622', '5.311', '5.838', '5.213'}\n",
      "95000\n",
      "{'5.1420', '5.1342', '5.251', '5.1571', '5.311', '5.838'}\n",
      "16\n",
      "{'5.1957', '5.1258', '5.68'}\n",
      "45000\n",
      "{'5.311'}\n",
      "32\n",
      "{'5.1138', '5.1298', '5.1585', '5.1739', '5.68', '5.347'}\n",
      "96000\n",
      "{'5.1420', '5.404', '5.302'}\n",
      "46000\n",
      "{'5.1622', '5.311', '5.213'}\n",
      "97000\n",
      "{'5.1420', '5.1571'}\n",
      "64\n",
      "{'5.1486', '5.1298', '5.1366'}\n",
      "47000\n",
      "{'5.1622', '5.311', '5.367'}\n",
      "98000\n",
      "{'5.302'}\n",
      "128\n",
      "{'5.1486', '5.1227', '5.121'}\n",
      "48000\n",
      "{'5.1175', '5.311', '5.213'}\n",
      "99000\n",
      "{'5.148', '5.1571', '5.302'}\n",
      "256\n",
      "{'5.1043'}\n",
      "49000\n",
      "{'5.311', '5.213'}\n",
      "100000\n",
      "{'5.838'}\n",
      "512\n",
      "{'5.1015', '5.1296'}\n",
      "50000\n",
      "{'5.311', '5.1644', '5.1132', '5.213'}\n",
      "101000\n",
      "{'5.1420', '5.1571', '5.838', '5.404', '5.302'}\n",
      "1000\n",
      "{'5.311'}\n",
      "51000\n",
      "{'5.311'}\n",
      "102000\n",
      "{'5.302', '5.148', '5.1573'}\n",
      "52000\n",
      "{'5.311'}\n",
      "103000\n",
      "{'5.251', '5.826', '5.302'}\n",
      "53000\n",
      "{'5.311', '5.213'}\n",
      "104000\n",
      "{'5.795'}\n",
      "4000\n",
      "{'5.838', '5.213'}\n",
      "54000\n",
      "{'5.311'}\n",
      "105000\n",
      "{'5.1420', '5.838', '5.1571'}\n",
      "5000\n",
      "{'5.838', '5.1780'}\n",
      "55000\n",
      "{'5.311', '5.213'}\n",
      "106000\n",
      "{'5.838', '5.1573'}\n",
      "6000\n",
      "{'5.311', '5.838', '5.427'}\n",
      "56000\n",
      "{'5.311'}\n",
      "107000\n",
      "{'5.838', '5.1571'}\n",
      "7000\n",
      "{'5.311'}\n",
      "57000\n",
      "{'5.311', '5.213'}\n",
      "108000\n",
      "{'5.1420', '5.838', '5.1571', '5.795'}\n",
      "58000\n",
      "{'5.311'}\n",
      "109000\n",
      "{'5.1420', '5.1571', '5.1573'}\n",
      "9000\n",
      "{'5.311', '5.838', '5.427', '5.213'}\n",
      "59000\n",
      "{'5.311', '5.213'}\n",
      "110000\n",
      "{'5.1420', '5.838', '5.1571'}\n",
      "10000\n",
      "{'5.311', '5.838', '5.427'}\n",
      "60000\n",
      "{'5.311'}\n",
      "111000\n",
      "{'5.826', '5.1573', '5.838', '5.302', '5.795'}\n",
      "11000\n",
      "{'5.311', '5.838', '5.427', '5.213'}\n",
      "61000\n",
      "{'5.311', '5.1277'}\n",
      "112000\n",
      "{'5.1420', '5.373', '5.795'}\n",
      "12000\n",
      "{'5.311', '5.838', '5.427'}\n",
      "62000\n",
      "{'5.311', '5.213'}\n",
      "113000\n",
      "{'5.838'}\n",
      "13000\n",
      "{'5.311', '5.838', '5.427', '5.213'}\n",
      "63000\n",
      "{'5.311'}\n",
      "114000\n",
      "{'5.838', '5.1571', '5.1631', '5.795'}\n",
      "14000\n",
      "{'5.1622', '5.311', '5.838', '5.427'}\n",
      "64000\n",
      "{'5.311', '5.1771', '5.213'}\n",
      "115000\n",
      "{'5.838', '5.1571', '5.1631'}\n",
      "15000\n",
      "{'5.311', '5.838', '5.427', '5.213'}\n",
      "65000\n",
      "{'5.311', '5.1342', '5.1525'}\n",
      "116000\n",
      "{'5.373', '5.795'}\n",
      "16000\n",
      "{'5.311', '5.838'}\n",
      "66000\n",
      "{'5.311', '5.320'}\n",
      "117000\n",
      "{'5.854', '5.1631'}\n",
      "17000\n",
      "{'5.311', '5.367', '5.838', '5.213'}\n",
      "118000\n",
      "{'5.795', '5.1573'}\n",
      "18000\n",
      "{'5.311', '5.838', '5.213'}\n",
      "68000\n",
      "{'5.311', '5.986'}\n",
      "119000\n",
      "{'5.373'}\n",
      "19000\n",
      "{'5.311', '5.213'}\n",
      "69000\n",
      "{'5.311', '5.638'}\n",
      "120000\n",
      "{'5.1420', '5.404'}\n",
      "20000\n",
      "{'5.311', '5.838', '5.427', '5.213'}\n",
      "70000\n",
      "{'5.311', '5.415', '5.986'}\n",
      "121000\n",
      "{'5.1420', '5.826'}\n",
      "21000\n",
      "{'5.1622', '5.311', '5.838', '5.213'}\n",
      "71000\n",
      "{'5.311', '5.1035', '5.1525'}\n",
      "122000\n",
      "{'5.838', '5.795'}\n",
      "22000\n",
      "{'5.1622', '5.213', '5.311', '5.838', '5.205'}\n",
      "72000\n",
      "{'5.311', '5.986'}\n",
      "123000\n",
      "{'5.1420'}\n",
      "23000\n",
      "{'5.1622', '5.838', '5.213'}\n",
      "73000\n",
      "{'5.311', '5.415'}\n",
      "74000\n",
      "{'5.311', '5.986', '5.1525'}\n",
      "24000\n",
      "{'5.1622', '5.311', '5.838', '5.213'}\n",
      "125000\n",
      "{'5.795'}\n",
      "75000\n",
      "{'5.311', '5.213'}\n",
      "25000\n",
      "{'5.1622', '5.311', '5.396', '5.213'}\n",
      "76000\n",
      "{'5.311', '5.986'}\n",
      "26000\n",
      "{'5.311', '5.213'}\n",
      "127000\n",
      "{'5.838', '5.826', '5.1631'}\n",
      "77000\n",
      "{'5.311'}\n",
      "27000\n",
      "{'5.1622', '5.311', '5.826', '5.213'}\n",
      "128000\n",
      "{'5.826', '5.1631'}\n",
      "78000\n",
      "{'5.311'}\n",
      "28000\n",
      "{'5.1622', '5.311', '5.213'}\n",
      "129000\n",
      "{'5.1571', '5.1631'}\n",
      "79000\n",
      "{'5.311', '5.1273'}\n",
      "29000\n",
      "{'5.1622', '5.190', '5.311', '5.213'}\n",
      "130000\n",
      "{'5.795', '5.302'}\n",
      "80000\n",
      "{'5.311', '5.728'}\n",
      "30000\n",
      "{'5.311', '5.396', '5.838', '5.213'}\n",
      "131000\n",
      "{'5.826'}\n",
      "31000\n",
      "{'5.1622', '5.311', '5.213'}\n",
      "132000\n",
      "{'5.1420', '5.838', '5.1571', '5.1631'}\n",
      "82000\n",
      "{'5.311', '5.986', '5.1525'}\n",
      "32000\n",
      "{'5.1622', '5.311', '5.213'}\n",
      "133000\n",
      "{'5.205'}\n",
      "83000\n",
      "{'5.302'}\n",
      "33000\n",
      "{'5.311', '5.213'}\n",
      "134000\n",
      "{'5.795', '5.373', '5.1691', '5.302'}\n",
      "84000\n",
      "{'5.311', '5.203', '5.986'}\n",
      "34000\n",
      "{'5.311', '5.367', '5.213'}\n",
      "135000\n",
      "{'5.838'}\n",
      "85000\n",
      "{'5.638', '5.320', '5.404'}\n",
      "35000\n",
      "{'5.1622', '5.311', '5.213'}\n",
      "136000\n",
      "{'5.1872'}\n",
      "86000\n",
      "{'5.311', '5.638', '5.302'}\n",
      "36000\n",
      "{'5.311', '5.638', '5.213'}\n",
      "137000\n",
      "{'5.373', '5.205'}\n",
      "87000\n",
      "{'5.311', '5.638', '5.203', '5.1342'}\n",
      "37000\n",
      "{'5.1622', '5.311', '5.213'}\n",
      "138000\n",
      "{'5.1420', '5.1631', '5.1872'}\n",
      "88000\n",
      "{'5.311', '5.320', '5.986', '5.302'}\n",
      "38000\n",
      "{'5.1622', '5.311', '5.213'}\n",
      "139000\n",
      "{'5.205'}\n",
      "89000\n",
      "{'5.203', '5.404', '5.302'}\n",
      "39000\n",
      "{'5.311', '5.213'}\n",
      "140000\n",
      "{'5.373', '5.1573'}\n",
      "141000\n",
      "{'5.205', '5.1573'}\n",
      "142000\n",
      "{'5.1175', '5.795', '5.1872'}\n",
      "143000\n",
      "{'5.826'}\n",
      "longtail:70m:10:None\n",
      "0\n",
      "{'23.185'}\n",
      "1\n",
      "{'23.1863', '23.1151', '23.1979', '23.1567'}\n",
      "2\n",
      "{'23.2291', '23.2820'}\n",
      "4\n",
      "{'23.1727'}\n",
      "8\n",
      "{'23.558', '23.413', '23.3141', '23.3046', '23.3984'}\n",
      "16\n",
      "{'23.3984', '23.1976', '23.413', '23.2497'}\n",
      "32\n",
      "{'23.2057'}\n",
      "64\n",
      "{'23.3758'}\n",
      "128\n",
      "{'23.4067', '23.3758'}\n",
      "512\n",
      "{'23.2572'}\n",
      "1000\n",
      "{'23.3778'}\n",
      "2000\n",
      "{'23.1477', '23.888'}\n",
      "60000\n",
      "{'23.884', '23.165', '23.2989', '23.3412', '23.3196'}\n",
      "61000\n",
      "{'23.884', '23.730', '23.2989', '23.3778', '23.2767', '23.2952', '23.1261'}\n",
      "3000\n",
      "{'23.879'}\n",
      "62000\n",
      "{'23.3778', '23.1630'}\n",
      "63000\n",
      "{'23.2952', '23.2515', '23.1630'}\n",
      "64000\n",
      "{'23.884', '23.879', '23.2989', '23.3778', '23.2952', '23.3196'}\n",
      "65000\n",
      "{'23.884', '23.3412', '23.2363', '23.1630', '23.3196'}\n",
      "66000\n",
      "{'23.884', '23.3778', '23.2952', '23.1630', '23.2363'}\n",
      "67000\n",
      "{'23.884', '23.2989', '23.3778', '23.2952', '23.1630'}\n",
      "68000\n",
      "{'23.884', '23.2515', '23.3778', '23.2767'}\n",
      "69000\n",
      "{'23.2515', '23.165', '23.3778', '23.2767', '23.1630'}\n",
      "70000\n",
      "{'23.3778'}\n",
      "9000\n",
      "{'23.2039'}\n",
      "12000\n",
      "{'23.51', '23.888'}\n",
      "13000\n",
      "{'23.3935'}\n",
      "14000\n",
      "{'23.3935', '23.2989', '23.1630'}\n",
      "15000\n",
      "{'23.3795', '23.1477', '23.51'}\n",
      "16000\n",
      "{'23.2952', '23.1360', '23.3412'}\n",
      "17000\n",
      "{'23.2952', '23.3935', '23.2989', '23.1477'}\n",
      "18000\n",
      "{'23.3935', '23.2989', '23.2732'}\n",
      "19000\n",
      "{'23.3795', '23.3412'}\n",
      "20000\n",
      "{'23.884', '23.2989', '23.3412'}\n",
      "21000\n",
      "{'23.165', '23.3412', '23.2767', '23.888', '23.2952', '23.3935', '23.1630'}\n",
      "22000\n",
      "{'23.3412'}\n",
      "23000\n",
      "{'23.884', '23.3778', '23.2952', '23.3935', '23.3412'}\n",
      "24000\n",
      "{'23.3778', '23.3412', '23.1261', '23.2767'}\n",
      "25000\n",
      "{'23.3412', '23.2989', '23.2952', '23.3935', '23.2039', '23.1630'}\n",
      "26000\n",
      "{'23.884', '23.2989', '23.3412'}\n",
      "27000\n",
      "{'23.3935'}\n",
      "28000\n",
      "{'23.884', '23.3412', '23.2767', '23.2952', '23.1261', '23.1630'}\n",
      "29000\n",
      "{'23.2515', '23.2952', '23.1261', '23.3412', '23.3196'}\n",
      "30000\n",
      "{'23.879', '23.2989', '23.2767', '23.2952', '23.3412'}\n",
      "31000\n",
      "{'23.165'}\n",
      "32000\n",
      "{'23.3412', '23.879', '23.2989', '23.3935', '23.1630', '23.3196'}\n",
      "33000\n",
      "{'23.3610'}\n",
      "34000\n",
      "{'23.3412', '23.879'}\n",
      "35000\n",
      "{'23.2989', '23.165', '23.3412', '23.3196'}\n",
      "36000\n",
      "{'23.3412', '23.1261'}\n",
      "37000\n",
      "{'23.2989', '23.165', '23.1630', '23.1261'}\n",
      "38000\n",
      "{'23.730', '23.2989', '23.165', '23.3412'}\n",
      "39000\n",
      "{'23.730', '23.2989', '23.1261', '23.3610', '23.3412', '23.3196'}\n",
      "40000\n",
      "{'23.2952', '23.730', '23.3412', '23.2039'}\n",
      "41000\n",
      "{'23.3412', '23.879', '23.2989', '23.3778', '23.1261', '23.2039'}\n",
      "42000\n",
      "{'23.3412', '23.2270', '23.2989', '23.888', '23.1261', '23.2039', '23.3196'}\n",
      "43000\n",
      "{'23.3412', '23.2989', '23.888', '23.2952', '23.1261', '23.1630'}\n",
      "44000\n",
      "{'23.2989', '23.2952', '23.1261', '23.3412', '23.3196'}\n",
      "45000\n",
      "{'23.1630'}\n",
      "46000\n",
      "{'23.879', '23.730', '23.2989', '23.3778', '23.2767', '23.2952', '23.3196'}\n",
      "47000\n",
      "{'23.2952', '23.513', '23.3778', '23.2767'}\n",
      "48000\n",
      "{'23.879', '23.2270', '23.2989', '23.1261', '23.2427', '23.3412', '23.3196'}\n",
      "49000\n",
      "{'23.884', '23.165', '23.2989', '23.3778', '23.2952', '23.3412'}\n",
      "50000\n",
      "{'23.2515', '23.2767', '23.2952', '23.1261', '23.3412', '23.3196'}\n",
      "51000\n",
      "{'23.165', '23.2989', '23.888', '23.1261', '23.3412', '23.3196'}\n",
      "52000\n",
      "{'23.3412', '23.2989', '23.3778', '23.2952', '23.1261', '23.2039'}\n",
      "53000\n",
      "{'23.884', '23.2515', '23.165', '23.2989', '23.3196'}\n",
      "54000\n",
      "{'23.884', '23.2515', '23.2989', '23.3778', '23.2952', '23.3412'}\n",
      "55000\n",
      "{'23.730', '23.2989', '23.2270', '23.2952', '23.3412'}\n",
      "56000\n",
      "{'23.884', '23.3778', '23.1630', '23.1261'}\n",
      "57000\n",
      "{'23.879', '23.730', '23.3778', '23.1261', '23.1630'}\n",
      "58000\n",
      "{'23.2952', '23.884', '23.165', '23.3778'}\n",
      "59000\n",
      "{'23.884', '23.3778', '23.2363'}\n",
      "71000\n",
      "{'23.2952', '23.1261', '23.1630', '23.879'}\n",
      "72000\n",
      "{'23.2767'}\n",
      "74000\n",
      "{'23.2515', '23.1630', '23.879'}\n",
      "75000\n",
      "{'23.2952', '23.3778', '23.1630', '23.3196'}\n",
      "77000\n",
      "{'23.884', '23.2515', '23.2363'}\n",
      "78000\n",
      "{'23.884', '23.1630'}\n",
      "79000\n",
      "{'23.2952', '23.884', '23.2767', '23.3196'}\n",
      "80000\n",
      "{'23.2952', '23.884', '23.3778'}\n",
      "81000\n",
      "{'23.884', '23.1630'}\n",
      "82000\n",
      "{'23.884', '23.2515', '23.2767', '23.2427', '23.1630'}\n",
      "84000\n",
      "{'23.2767'}\n",
      "86000\n",
      "{'23.884', '23.2515', '23.3778'}\n",
      "87000\n",
      "{'23.884', '23.2515', '23.3778', '23.2767', '23.1630'}\n",
      "89000\n",
      "{'23.884', '23.1630'}\n",
      "90000\n",
      "{'23.2039', '23.1630'}\n",
      "92000\n",
      "{'23.1630'}\n",
      "93000\n",
      "{'23.1630'}\n",
      "94000\n",
      "{'23.884', '23.2767'}\n",
      "95000\n",
      "{'23.2515', '23.3778', '23.1630', '23.2427'}\n",
      "96000\n",
      "{'23.884', '23.3196', '23.2767', '23.2363'}\n",
      "97000\n",
      "{'23.884', '23.1630', '23.2767'}\n",
      "99000\n",
      "{'23.884', '23.3778'}\n",
      "100000\n",
      "{'23.884', '23.2515', '23.2767'}\n",
      "103000\n",
      "{'23.1630'}\n",
      "104000\n",
      "{'23.884'}\n",
      "110000\n",
      "{'23.1630'}\n",
      "119000\n",
      "{'23.1630'}\n",
      "128000\n",
      "{'23.2152'}\n",
      "longtail:410m:10:None\n",
      "0\n",
      "{'5.1219', '5.276', '5.1299'}\n",
      "1\n",
      "{'5.1219', '5.276', '5.1299'}\n",
      "2\n",
      "{'5.276', '5.1299'}\n",
      "16\n",
      "{'5.1917'}\n",
      "1000\n",
      "{'5.311'}\n",
      "2000\n",
      "{'5.427'}\n",
      "5000\n",
      "{'5.900', '5.838'}\n",
      "12000\n",
      "{'5.984'}\n",
      "13000\n",
      "{'5.427'}\n",
      "17000\n",
      "{'5.794'}\n",
      "18000\n",
      "{'5.922'}\n",
      "24000\n",
      "{'5.364'}\n",
      "26000\n",
      "{'5.934'}\n",
      "27000\n",
      "{'5.1561'}\n",
      "34000\n",
      "{'5.838'}\n",
      "38000\n",
      "{'5.9'}\n",
      "45000\n",
      "{'5.2029'}\n",
      "46000\n",
      "{'5.1224'}\n",
      "48000\n",
      "{'5.634'}\n",
      "49000\n",
      "{'5.1718', '5.339'}\n",
      "52000\n",
      "{'5.1928'}\n",
      "53000\n",
      "{'5.339'}\n",
      "55000\n",
      "{'5.1440'}\n",
      "56000\n",
      "{'5.13'}\n",
      "57000\n",
      "{'5.95'}\n",
      "65000\n",
      "{'5.1833'}\n",
      "66000\n",
      "{'5.450'}\n",
      "70000\n",
      "{'5.684'}\n",
      "74000\n",
      "{'5.1129'}\n",
      "79000\n",
      "{'5.1129'}\n",
      "80000\n",
      "{'5.388'}\n",
      "83000\n",
      "{'5.101'}\n",
      "84000\n",
      "{'5.836'}\n",
      "85000\n",
      "{'5.1811'}\n",
      "86000\n",
      "{'5.540'}\n",
      "87000\n",
      "{'5.999'}\n",
      "91000\n",
      "{'5.932'}\n",
      "93000\n",
      "{'5.1440'}\n",
      "99000\n",
      "{'5.391'}\n",
      "100000\n",
      "{'5.1741'}\n",
      "101000\n",
      "{'5.520', '5.102'}\n",
      "103000\n",
      "{'5.1248'}\n",
      "104000\n",
      "{'5.1025'}\n",
      "106000\n",
      "{'5.487'}\n",
      "107000\n",
      "{'5.1222'}\n",
      "109000\n",
      "{'5.1546'}\n",
      "111000\n",
      "{'5.922', '5.1195'}\n",
      "112000\n",
      "{'5.520'}\n",
      "115000\n",
      "{'5.922', '5.520'}\n",
      "122000\n",
      "{'5.1864'}\n",
      "124000\n",
      "{'5.104'}\n",
      "129000\n",
      "{'5.608'}\n",
      "131000\n",
      "{'5.1944'}\n",
      "136000\n",
      "{'5.335'}\n",
      "mean:70m:10:None\n",
      "0\n",
      "{'23.1277', '23.4036'}\n",
      "1\n",
      "{'23.1277', '23.4036'}\n",
      "4\n",
      "{'23.1193'}\n",
      "64\n",
      "{'23.2472'}\n",
      "3000\n",
      "{'23.1360'}\n",
      "4000\n",
      "{'23.1477'}\n",
      "5000\n",
      "{'23.165'}\n",
      "8000\n",
      "{'23.2270', '23.614'}\n",
      "9000\n",
      "{'23.1360'}\n",
      "10000\n",
      "{'23.513'}\n",
      "11000\n",
      "{'23.2062'}\n",
      "15000\n",
      "{'23.884', '23.879'}\n",
      "17000\n",
      "{'23.2062'}\n",
      "19000\n",
      "{'23.2062', '23.513'}\n",
      "20000\n",
      "{'23.884', '23.3778', '23.3412'}\n",
      "23000\n",
      "{'23.3610'}\n",
      "25000\n",
      "{'23.730', '23.2270'}\n",
      "27000\n",
      "{'23.2062'}\n",
      "29000\n",
      "{'23.2952'}\n",
      "30000\n",
      "{'23.879'}\n",
      "31000\n",
      "{'23.730', '23.1261'}\n",
      "32000\n",
      "{'23.513'}\n",
      "36000\n",
      "{'23.2270', '23.513', '23.3610'}\n",
      "37000\n",
      "{'23.2952', '23.2039', '23.888'}\n",
      "38000\n",
      "{'23.730'}\n",
      "39000\n",
      "{'23.3412'}\n",
      "40000\n",
      "{'23.2039'}\n",
      "41000\n",
      "{'23.2039', '23.3412'}\n",
      "42000\n",
      "{'23.884'}\n",
      "43000\n",
      "{'23.2270', '23.165'}\n",
      "44000\n",
      "{'23.2952'}\n",
      "45000\n",
      "{'23.2952', '23.884'}\n",
      "46000\n",
      "{'23.165', '23.888'}\n",
      "47000\n",
      "{'23.614'}\n",
      "48000\n",
      "{'23.730'}\n",
      "50000\n",
      "{'23.2062', '23.730', '23.2515', '23.165'}\n",
      "51000\n",
      "{'23.513'}\n",
      "52000\n",
      "{'23.884', '23.2515', '23.165'}\n",
      "55000\n",
      "{'23.513', '23.2039'}\n",
      "57000\n",
      "{'23.614'}\n",
      "59000\n",
      "{'23.3778', '23.614'}\n",
      "60000\n",
      "{'23.2952', '23.3587'}\n",
      "61000\n",
      "{'23.513', '23.3778', '23.2039', '23.614'}\n",
      "62000\n",
      "{'23.3778'}\n",
      "66000\n",
      "{'23.888'}\n",
      "67000\n",
      "{'23.2515', '23.3778', '23.2767'}\n",
      "68000\n",
      "{'23.2952'}\n",
      "69000\n",
      "{'23.2952', '23.513'}\n",
      "70000\n",
      "{'23.730'}\n",
      "75000\n",
      "{'23.1630'}\n",
      "77000\n",
      "{'23.2270', '23.3778'}\n",
      "78000\n",
      "{'23.1630'}\n",
      "80000\n",
      "{'23.884', '23.2515', '23.1630'}\n",
      "81000\n",
      "{'23.1261'}\n",
      "82000\n",
      "{'23.1261', '23.275'}\n",
      "84000\n",
      "{'23.2039'}\n",
      "85000\n",
      "{'23.2039'}\n",
      "86000\n",
      "{'23.2039'}\n",
      "87000\n",
      "{'23.2039', '23.1481', '23.1630'}\n",
      "88000\n",
      "{'23.2515'}\n",
      "90000\n",
      "{'23.2039'}\n",
      "91000\n",
      "{'23.1630', '23.2767'}\n",
      "92000\n",
      "{'23.884'}\n",
      "94000\n",
      "{'23.884'}\n",
      "96000\n",
      "{'23.2515'}\n",
      "98000\n",
      "{'23.2515'}\n",
      "99000\n",
      "{'23.2767'}\n",
      "100000\n",
      "{'23.1630'}\n",
      "103000\n",
      "{'23.1261'}\n",
      "105000\n",
      "{'23.513', '23.2767'}\n",
      "106000\n",
      "{'23.2767'}\n",
      "107000\n",
      "{'23.2515', '23.3778'}\n",
      "110000\n",
      "{'23.3935'}\n",
      "112000\n",
      "{'23.884'}\n",
      "113000\n",
      "{'23.2515'}\n",
      "115000\n",
      "{'23.2952'}\n",
      "mean:410m:10:None\n"
     ]
    }
   ],
   "source": [
    "neuron_name = [10]\n",
    "models = [\"70m\",\"410m\"]\n",
    "vecs = [\"longtail\",\"mean\"]\n",
    "for vec in vecs:\n",
    "    for model in models:\n",
    "        for neuron_num in neuron_name:\n",
    "            print(f\"{vec}:{model}:{neuron_num}:{compare_idx(neuron_path,vec,model,neuron_num)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inspect full ablation exp: .feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path(\"/Users/jliu/workspace/RAG/\")\n",
    "ablation_path = ROOT / \"results\" / \"ablations\"\n",
    "neuron_path = ROOT / \"results\" / \"token_freq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'str_tokens', 'unique_token', 'context', 'batch', 'pos',\n",
       "       'label', 'token_id', 'entropy', 'top_logit', 'pred', 'loss', 'top_logp',\n",
       "       'ln_final_scale', 'rank_of_correct_token', 'correct_token_rank',\n",
       "       'pred_in_top1', 'pred_in_top5', 'activation', 'component_name',\n",
       "       'loss_post_ablation', 'loss_post_ablation_with_frozen_unigram',\n",
       "       'entropy_post_ablation', 'entropy_post_ablation_with_frozen_unigram',\n",
       "       'kl_divergence_before', 'kl_divergence_after',\n",
       "       'kl_divergence_after_frozen_unigram', 'ablation_mode',\n",
       "       'longtail_threshold', 'num_longtail_tokens'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feather_path = ROOT / \"results\" / \"k10.feather\"\n",
    "data = pd.read_feather(feather_path)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>str_tokens</th>\n",
       "      <th>unique_token</th>\n",
       "      <th>context</th>\n",
       "      <th>batch</th>\n",
       "      <th>pos</th>\n",
       "      <th>label</th>\n",
       "      <th>token_id</th>\n",
       "      <th>entropy</th>\n",
       "      <th>top_logit</th>\n",
       "      <th>...</th>\n",
       "      <th>loss_post_ablation</th>\n",
       "      <th>loss_post_ablation_with_frozen_unigram</th>\n",
       "      <th>entropy_post_ablation</th>\n",
       "      <th>entropy_post_ablation_with_frozen_unigram</th>\n",
       "      <th>kl_divergence_before</th>\n",
       "      <th>kl_divergence_after</th>\n",
       "      <th>kl_divergence_after_frozen_unigram</th>\n",
       "      <th>ablation_mode</th>\n",
       "      <th>longtail_threshold</th>\n",
       "      <th>num_longtail_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16899</td>\n",
       "      <td>of</td>\n",
       "      <td>of/3</td>\n",
       "      <td>&lt;|endoftext|&gt; the type| of| person</td>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>66/3</td>\n",
       "      <td>273</td>\n",
       "      <td>10.625110</td>\n",
       "      <td>2.644757</td>\n",
       "      <td>...</td>\n",
       "      <td>11.593288</td>\n",
       "      <td>11.592592</td>\n",
       "      <td>10.625118</td>\n",
       "      <td>10.625124</td>\n",
       "      <td>1.843616</td>\n",
       "      <td>1.843621</td>\n",
       "      <td>3.498532</td>\n",
       "      <td>longtail</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>25152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16900</td>\n",
       "      <td>person</td>\n",
       "      <td>person/4</td>\n",
       "      <td>&lt;|endoftext|&gt; the type of| person| who</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>66/4</td>\n",
       "      <td>1436</td>\n",
       "      <td>10.625622</td>\n",
       "      <td>2.433045</td>\n",
       "      <td>...</td>\n",
       "      <td>10.606367</td>\n",
       "      <td>10.604810</td>\n",
       "      <td>10.625614</td>\n",
       "      <td>10.625614</td>\n",
       "      <td>1.838244</td>\n",
       "      <td>1.838215</td>\n",
       "      <td>3.497498</td>\n",
       "      <td>longtail</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>25152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16901</td>\n",
       "      <td>who</td>\n",
       "      <td>who/5</td>\n",
       "      <td>&lt;|endoftext|&gt; the type of person| who| would</td>\n",
       "      <td>66</td>\n",
       "      <td>5</td>\n",
       "      <td>66/5</td>\n",
       "      <td>665</td>\n",
       "      <td>10.626801</td>\n",
       "      <td>2.704882</td>\n",
       "      <td>...</td>\n",
       "      <td>10.619455</td>\n",
       "      <td>10.619543</td>\n",
       "      <td>10.626811</td>\n",
       "      <td>10.626803</td>\n",
       "      <td>1.831392</td>\n",
       "      <td>1.831393</td>\n",
       "      <td>3.478915</td>\n",
       "      <td>longtail</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>25152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16902</td>\n",
       "      <td>would</td>\n",
       "      <td>would/6</td>\n",
       "      <td>the type of person who| would| boil</td>\n",
       "      <td>66</td>\n",
       "      <td>6</td>\n",
       "      <td>66/6</td>\n",
       "      <td>651</td>\n",
       "      <td>10.624903</td>\n",
       "      <td>2.651785</td>\n",
       "      <td>...</td>\n",
       "      <td>9.778926</td>\n",
       "      <td>9.779284</td>\n",
       "      <td>10.624899</td>\n",
       "      <td>10.624900</td>\n",
       "      <td>1.832892</td>\n",
       "      <td>1.832924</td>\n",
       "      <td>3.483242</td>\n",
       "      <td>longtail</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>25152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16903</td>\n",
       "      <td>boil</td>\n",
       "      <td>boil/7</td>\n",
       "      <td>type of person who would| boil| a</td>\n",
       "      <td>66</td>\n",
       "      <td>7</td>\n",
       "      <td>66/7</td>\n",
       "      <td>22149</td>\n",
       "      <td>10.628463</td>\n",
       "      <td>3.035857</td>\n",
       "      <td>...</td>\n",
       "      <td>11.647036</td>\n",
       "      <td>11.643663</td>\n",
       "      <td>10.628469</td>\n",
       "      <td>10.628471</td>\n",
       "      <td>1.842612</td>\n",
       "      <td>1.842553</td>\n",
       "      <td>3.492301</td>\n",
       "      <td>longtail</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>25152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4628727</th>\n",
       "      <td>218362</td>\n",
       "      <td>customers</td>\n",
       "      <td>customers/250</td>\n",
       "      <td>bring you closer to your| customers|.</td>\n",
       "      <td>852</td>\n",
       "      <td>250</td>\n",
       "      <td>852/250</td>\n",
       "      <td>6383</td>\n",
       "      <td>10.624666</td>\n",
       "      <td>3.056127</td>\n",
       "      <td>...</td>\n",
       "      <td>10.244482</td>\n",
       "      <td>10.245748</td>\n",
       "      <td>10.624682</td>\n",
       "      <td>10.624682</td>\n",
       "      <td>1.830016</td>\n",
       "      <td>1.830032</td>\n",
       "      <td>3.477154</td>\n",
       "      <td>longtail</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>25152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4628728</th>\n",
       "      <td>218363</td>\n",
       "      <td>.</td>\n",
       "      <td>./251</td>\n",
       "      <td>you closer to your customers|.| Like</td>\n",
       "      <td>852</td>\n",
       "      <td>251</td>\n",
       "      <td>852/251</td>\n",
       "      <td>15</td>\n",
       "      <td>10.624297</td>\n",
       "      <td>2.692122</td>\n",
       "      <td>...</td>\n",
       "      <td>10.630770</td>\n",
       "      <td>10.631306</td>\n",
       "      <td>10.624298</td>\n",
       "      <td>10.624296</td>\n",
       "      <td>1.823687</td>\n",
       "      <td>1.823693</td>\n",
       "      <td>3.480132</td>\n",
       "      <td>longtail</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>25152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4628729</th>\n",
       "      <td>218364</td>\n",
       "      <td>Like</td>\n",
       "      <td>Like/252</td>\n",
       "      <td>closer to your customers.| Like| other</td>\n",
       "      <td>852</td>\n",
       "      <td>252</td>\n",
       "      <td>852/252</td>\n",
       "      <td>6975</td>\n",
       "      <td>10.625395</td>\n",
       "      <td>2.611685</td>\n",
       "      <td>...</td>\n",
       "      <td>11.074329</td>\n",
       "      <td>11.075529</td>\n",
       "      <td>10.625385</td>\n",
       "      <td>10.625390</td>\n",
       "      <td>1.838073</td>\n",
       "      <td>1.838103</td>\n",
       "      <td>3.488963</td>\n",
       "      <td>longtail</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>25152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4628730</th>\n",
       "      <td>218365</td>\n",
       "      <td>other</td>\n",
       "      <td>other/253</td>\n",
       "      <td>to your customers. Like| other| channels</td>\n",
       "      <td>852</td>\n",
       "      <td>253</td>\n",
       "      <td>852/253</td>\n",
       "      <td>643</td>\n",
       "      <td>10.627460</td>\n",
       "      <td>2.413682</td>\n",
       "      <td>...</td>\n",
       "      <td>11.171703</td>\n",
       "      <td>11.172037</td>\n",
       "      <td>10.627460</td>\n",
       "      <td>10.627462</td>\n",
       "      <td>1.831767</td>\n",
       "      <td>1.831775</td>\n",
       "      <td>3.476629</td>\n",
       "      <td>longtail</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>25152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4628731</th>\n",
       "      <td>218366</td>\n",
       "      <td>channels</td>\n",
       "      <td>channels/254</td>\n",
       "      <td>your customers. Like other| channels|</td>\n",
       "      <td>852</td>\n",
       "      <td>254</td>\n",
       "      <td>852/254</td>\n",
       "      <td>8123</td>\n",
       "      <td>10.627494</td>\n",
       "      <td>2.554797</td>\n",
       "      <td>...</td>\n",
       "      <td>11.905016</td>\n",
       "      <td>11.911119</td>\n",
       "      <td>10.627488</td>\n",
       "      <td>10.627489</td>\n",
       "      <td>1.829526</td>\n",
       "      <td>1.829602</td>\n",
       "      <td>3.481620</td>\n",
       "      <td>longtail</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>25152.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2512 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          index  str_tokens    unique_token  \\\n",
       "0         16899          of            of/3   \n",
       "1         16900      person        person/4   \n",
       "2         16901         who           who/5   \n",
       "3         16902       would         would/6   \n",
       "4         16903        boil          boil/7   \n",
       "...         ...         ...             ...   \n",
       "4628727  218362   customers   customers/250   \n",
       "4628728  218363           .           ./251   \n",
       "4628729  218364        Like        Like/252   \n",
       "4628730  218365       other       other/253   \n",
       "4628731  218366    channels    channels/254   \n",
       "\n",
       "                                              context  batch  pos    label  \\\n",
       "0                  <|endoftext|> the type| of| person     66    3     66/3   \n",
       "1              <|endoftext|> the type of| person| who     66    4     66/4   \n",
       "2        <|endoftext|> the type of person| who| would     66    5     66/5   \n",
       "3                 the type of person who| would| boil     66    6     66/6   \n",
       "4                   type of person who would| boil| a     66    7     66/7   \n",
       "...                                               ...    ...  ...      ...   \n",
       "4628727         bring you closer to your| customers|.    852  250  852/250   \n",
       "4628728          you closer to your customers|.| Like    852  251  852/251   \n",
       "4628729        closer to your customers.| Like| other    852  252  852/252   \n",
       "4628730      to your customers. Like| other| channels    852  253  852/253   \n",
       "4628731         your customers. Like other| channels|    852  254  852/254   \n",
       "\n",
       "         token_id    entropy  top_logit  ...  loss_post_ablation  \\\n",
       "0             273  10.625110   2.644757  ...           11.593288   \n",
       "1            1436  10.625622   2.433045  ...           10.606367   \n",
       "2             665  10.626801   2.704882  ...           10.619455   \n",
       "3             651  10.624903   2.651785  ...            9.778926   \n",
       "4           22149  10.628463   3.035857  ...           11.647036   \n",
       "...           ...        ...        ...  ...                 ...   \n",
       "4628727      6383  10.624666   3.056127  ...           10.244482   \n",
       "4628728        15  10.624297   2.692122  ...           10.630770   \n",
       "4628729      6975  10.625395   2.611685  ...           11.074329   \n",
       "4628730       643  10.627460   2.413682  ...           11.171703   \n",
       "4628731      8123  10.627494   2.554797  ...           11.905016   \n",
       "\n",
       "         loss_post_ablation_with_frozen_unigram  entropy_post_ablation  \\\n",
       "0                                     11.592592              10.625118   \n",
       "1                                     10.604810              10.625614   \n",
       "2                                     10.619543              10.626811   \n",
       "3                                      9.779284              10.624899   \n",
       "4                                     11.643663              10.628469   \n",
       "...                                         ...                    ...   \n",
       "4628727                               10.245748              10.624682   \n",
       "4628728                               10.631306              10.624298   \n",
       "4628729                               11.075529              10.625385   \n",
       "4628730                               11.172037              10.627460   \n",
       "4628731                               11.911119              10.627488   \n",
       "\n",
       "         entropy_post_ablation_with_frozen_unigram  kl_divergence_before  \\\n",
       "0                                        10.625124              1.843616   \n",
       "1                                        10.625614              1.838244   \n",
       "2                                        10.626803              1.831392   \n",
       "3                                        10.624900              1.832892   \n",
       "4                                        10.628471              1.842612   \n",
       "...                                            ...                   ...   \n",
       "4628727                                  10.624682              1.830016   \n",
       "4628728                                  10.624296              1.823687   \n",
       "4628729                                  10.625390              1.838073   \n",
       "4628730                                  10.627462              1.831767   \n",
       "4628731                                  10.627489              1.829526   \n",
       "\n",
       "         kl_divergence_after  kl_divergence_after_frozen_unigram  \\\n",
       "0                   1.843621                            3.498532   \n",
       "1                   1.838215                            3.497498   \n",
       "2                   1.831393                            3.478915   \n",
       "3                   1.832924                            3.483242   \n",
       "4                   1.842553                            3.492301   \n",
       "...                      ...                                 ...   \n",
       "4628727             1.830032                            3.477154   \n",
       "4628728             1.823693                            3.480132   \n",
       "4628729             1.838103                            3.488963   \n",
       "4628730             1.831775                            3.476629   \n",
       "4628731             1.829602                            3.481620   \n",
       "\n",
       "         ablation_mode  longtail_threshold num_longtail_tokens  \n",
       "0             longtail            0.000003             25152.0  \n",
       "1             longtail            0.000003             25152.0  \n",
       "2             longtail            0.000003             25152.0  \n",
       "3             longtail            0.000003             25152.0  \n",
       "4             longtail            0.000003             25152.0  \n",
       "...                ...                 ...                 ...  \n",
       "4628727       longtail            0.000003             25152.0  \n",
       "4628728       longtail            0.000003             25152.0  \n",
       "4628729       longtail            0.000003             25152.0  \n",
       "4628730       longtail            0.000003             25152.0  \n",
       "4628731       longtail            0.000003             25152.0  \n",
       "\n",
       "[2512 rows x 30 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['component_name']==\"5.0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>str_tokens</th>\n",
       "      <th>unique_token</th>\n",
       "      <th>context</th>\n",
       "      <th>batch</th>\n",
       "      <th>pos</th>\n",
       "      <th>label</th>\n",
       "      <th>token_id</th>\n",
       "      <th>entropy</th>\n",
       "      <th>top_logit</th>\n",
       "      <th>...</th>\n",
       "      <th>loss_post_ablation</th>\n",
       "      <th>loss_post_ablation_with_frozen_unigram</th>\n",
       "      <th>entropy_post_ablation</th>\n",
       "      <th>entropy_post_ablation_with_frozen_unigram</th>\n",
       "      <th>kl_divergence_before</th>\n",
       "      <th>kl_divergence_after</th>\n",
       "      <th>kl_divergence_after_frozen_unigram</th>\n",
       "      <th>ablation_mode</th>\n",
       "      <th>longtail_threshold</th>\n",
       "      <th>num_longtail_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>16899</td>\n",
       "      <td>of</td>\n",
       "      <td>of/3</td>\n",
       "      <td>&lt;|endoftext|&gt; the type| of| person</td>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>66/3</td>\n",
       "      <td>273</td>\n",
       "      <td>10.625110</td>\n",
       "      <td>2.644757</td>\n",
       "      <td>...</td>\n",
       "      <td>11.596313</td>\n",
       "      <td>11.592589</td>\n",
       "      <td>10.625127</td>\n",
       "      <td>10.625122</td>\n",
       "      <td>1.843616</td>\n",
       "      <td>1.843612</td>\n",
       "      <td>3.498574</td>\n",
       "      <td>longtail</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>25152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>16900</td>\n",
       "      <td>person</td>\n",
       "      <td>person/4</td>\n",
       "      <td>&lt;|endoftext|&gt; the type of| person| who</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>66/4</td>\n",
       "      <td>1436</td>\n",
       "      <td>10.625622</td>\n",
       "      <td>2.433045</td>\n",
       "      <td>...</td>\n",
       "      <td>10.603323</td>\n",
       "      <td>10.604815</td>\n",
       "      <td>10.625612</td>\n",
       "      <td>10.625620</td>\n",
       "      <td>1.838244</td>\n",
       "      <td>1.838241</td>\n",
       "      <td>3.497475</td>\n",
       "      <td>longtail</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>25152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>16901</td>\n",
       "      <td>who</td>\n",
       "      <td>who/5</td>\n",
       "      <td>&lt;|endoftext|&gt; the type of person| who| would</td>\n",
       "      <td>66</td>\n",
       "      <td>5</td>\n",
       "      <td>66/5</td>\n",
       "      <td>665</td>\n",
       "      <td>10.626801</td>\n",
       "      <td>2.704882</td>\n",
       "      <td>...</td>\n",
       "      <td>10.617924</td>\n",
       "      <td>10.619536</td>\n",
       "      <td>10.626818</td>\n",
       "      <td>10.626801</td>\n",
       "      <td>1.831392</td>\n",
       "      <td>1.831377</td>\n",
       "      <td>3.478915</td>\n",
       "      <td>longtail</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>25152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>16902</td>\n",
       "      <td>would</td>\n",
       "      <td>would/6</td>\n",
       "      <td>the type of person who| would| boil</td>\n",
       "      <td>66</td>\n",
       "      <td>6</td>\n",
       "      <td>66/6</td>\n",
       "      <td>651</td>\n",
       "      <td>10.624903</td>\n",
       "      <td>2.651785</td>\n",
       "      <td>...</td>\n",
       "      <td>9.776935</td>\n",
       "      <td>9.779279</td>\n",
       "      <td>10.624906</td>\n",
       "      <td>10.624899</td>\n",
       "      <td>1.832892</td>\n",
       "      <td>1.832879</td>\n",
       "      <td>3.483268</td>\n",
       "      <td>longtail</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>25152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>16903</td>\n",
       "      <td>boil</td>\n",
       "      <td>boil/7</td>\n",
       "      <td>type of person who would| boil| a</td>\n",
       "      <td>66</td>\n",
       "      <td>7</td>\n",
       "      <td>66/7</td>\n",
       "      <td>22149</td>\n",
       "      <td>10.628463</td>\n",
       "      <td>3.035857</td>\n",
       "      <td>...</td>\n",
       "      <td>11.644431</td>\n",
       "      <td>11.643667</td>\n",
       "      <td>10.628453</td>\n",
       "      <td>10.628458</td>\n",
       "      <td>1.842612</td>\n",
       "      <td>1.842607</td>\n",
       "      <td>3.492335</td>\n",
       "      <td>longtail</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>25152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4628979</th>\n",
       "      <td>218362</td>\n",
       "      <td>customers</td>\n",
       "      <td>customers/250</td>\n",
       "      <td>bring you closer to your| customers|.</td>\n",
       "      <td>852</td>\n",
       "      <td>250</td>\n",
       "      <td>852/250</td>\n",
       "      <td>6383</td>\n",
       "      <td>10.624666</td>\n",
       "      <td>3.056127</td>\n",
       "      <td>...</td>\n",
       "      <td>10.246298</td>\n",
       "      <td>10.245765</td>\n",
       "      <td>10.624675</td>\n",
       "      <td>10.624657</td>\n",
       "      <td>1.830016</td>\n",
       "      <td>1.830017</td>\n",
       "      <td>3.477201</td>\n",
       "      <td>longtail</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>25152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4628980</th>\n",
       "      <td>218363</td>\n",
       "      <td>.</td>\n",
       "      <td>./251</td>\n",
       "      <td>you closer to your customers|.| Like</td>\n",
       "      <td>852</td>\n",
       "      <td>251</td>\n",
       "      <td>852/251</td>\n",
       "      <td>15</td>\n",
       "      <td>10.624297</td>\n",
       "      <td>2.692122</td>\n",
       "      <td>...</td>\n",
       "      <td>10.631807</td>\n",
       "      <td>10.631309</td>\n",
       "      <td>10.624298</td>\n",
       "      <td>10.624294</td>\n",
       "      <td>1.823687</td>\n",
       "      <td>1.823684</td>\n",
       "      <td>3.480128</td>\n",
       "      <td>longtail</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>25152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4628981</th>\n",
       "      <td>218364</td>\n",
       "      <td>Like</td>\n",
       "      <td>Like/252</td>\n",
       "      <td>closer to your customers.| Like| other</td>\n",
       "      <td>852</td>\n",
       "      <td>252</td>\n",
       "      <td>852/252</td>\n",
       "      <td>6975</td>\n",
       "      <td>10.625395</td>\n",
       "      <td>2.611685</td>\n",
       "      <td>...</td>\n",
       "      <td>11.073826</td>\n",
       "      <td>11.075520</td>\n",
       "      <td>10.625405</td>\n",
       "      <td>10.625399</td>\n",
       "      <td>1.838073</td>\n",
       "      <td>1.838057</td>\n",
       "      <td>3.488969</td>\n",
       "      <td>longtail</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>25152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4628982</th>\n",
       "      <td>218365</td>\n",
       "      <td>other</td>\n",
       "      <td>other/253</td>\n",
       "      <td>to your customers. Like| other| channels</td>\n",
       "      <td>852</td>\n",
       "      <td>253</td>\n",
       "      <td>852/253</td>\n",
       "      <td>643</td>\n",
       "      <td>10.627460</td>\n",
       "      <td>2.413682</td>\n",
       "      <td>...</td>\n",
       "      <td>11.171778</td>\n",
       "      <td>11.172041</td>\n",
       "      <td>10.627459</td>\n",
       "      <td>10.627472</td>\n",
       "      <td>1.831767</td>\n",
       "      <td>1.831775</td>\n",
       "      <td>3.476626</td>\n",
       "      <td>longtail</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>25152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4628983</th>\n",
       "      <td>218366</td>\n",
       "      <td>channels</td>\n",
       "      <td>channels/254</td>\n",
       "      <td>your customers. Like other| channels|</td>\n",
       "      <td>852</td>\n",
       "      <td>254</td>\n",
       "      <td>852/254</td>\n",
       "      <td>8123</td>\n",
       "      <td>10.627494</td>\n",
       "      <td>2.554797</td>\n",
       "      <td>...</td>\n",
       "      <td>11.907015</td>\n",
       "      <td>11.911097</td>\n",
       "      <td>10.627508</td>\n",
       "      <td>10.627515</td>\n",
       "      <td>1.829526</td>\n",
       "      <td>1.829497</td>\n",
       "      <td>3.481569</td>\n",
       "      <td>longtail</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>25152.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2512 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          index  str_tokens    unique_token  \\\n",
       "252       16899          of            of/3   \n",
       "253       16900      person        person/4   \n",
       "254       16901         who           who/5   \n",
       "255       16902       would         would/6   \n",
       "256       16903        boil          boil/7   \n",
       "...         ...         ...             ...   \n",
       "4628979  218362   customers   customers/250   \n",
       "4628980  218363           .           ./251   \n",
       "4628981  218364        Like        Like/252   \n",
       "4628982  218365       other       other/253   \n",
       "4628983  218366    channels    channels/254   \n",
       "\n",
       "                                              context  batch  pos    label  \\\n",
       "252                <|endoftext|> the type| of| person     66    3     66/3   \n",
       "253            <|endoftext|> the type of| person| who     66    4     66/4   \n",
       "254      <|endoftext|> the type of person| who| would     66    5     66/5   \n",
       "255               the type of person who| would| boil     66    6     66/6   \n",
       "256                 type of person who would| boil| a     66    7     66/7   \n",
       "...                                               ...    ...  ...      ...   \n",
       "4628979         bring you closer to your| customers|.    852  250  852/250   \n",
       "4628980          you closer to your customers|.| Like    852  251  852/251   \n",
       "4628981        closer to your customers.| Like| other    852  252  852/252   \n",
       "4628982      to your customers. Like| other| channels    852  253  852/253   \n",
       "4628983         your customers. Like other| channels|    852  254  852/254   \n",
       "\n",
       "         token_id    entropy  top_logit  ...  loss_post_ablation  \\\n",
       "252           273  10.625110   2.644757  ...           11.596313   \n",
       "253          1436  10.625622   2.433045  ...           10.603323   \n",
       "254           665  10.626801   2.704882  ...           10.617924   \n",
       "255           651  10.624903   2.651785  ...            9.776935   \n",
       "256         22149  10.628463   3.035857  ...           11.644431   \n",
       "...           ...        ...        ...  ...                 ...   \n",
       "4628979      6383  10.624666   3.056127  ...           10.246298   \n",
       "4628980        15  10.624297   2.692122  ...           10.631807   \n",
       "4628981      6975  10.625395   2.611685  ...           11.073826   \n",
       "4628982       643  10.627460   2.413682  ...           11.171778   \n",
       "4628983      8123  10.627494   2.554797  ...           11.907015   \n",
       "\n",
       "         loss_post_ablation_with_frozen_unigram  entropy_post_ablation  \\\n",
       "252                                   11.592589              10.625127   \n",
       "253                                   10.604815              10.625612   \n",
       "254                                   10.619536              10.626818   \n",
       "255                                    9.779279              10.624906   \n",
       "256                                   11.643667              10.628453   \n",
       "...                                         ...                    ...   \n",
       "4628979                               10.245765              10.624675   \n",
       "4628980                               10.631309              10.624298   \n",
       "4628981                               11.075520              10.625405   \n",
       "4628982                               11.172041              10.627459   \n",
       "4628983                               11.911097              10.627508   \n",
       "\n",
       "         entropy_post_ablation_with_frozen_unigram  kl_divergence_before  \\\n",
       "252                                      10.625122              1.843616   \n",
       "253                                      10.625620              1.838244   \n",
       "254                                      10.626801              1.831392   \n",
       "255                                      10.624899              1.832892   \n",
       "256                                      10.628458              1.842612   \n",
       "...                                            ...                   ...   \n",
       "4628979                                  10.624657              1.830016   \n",
       "4628980                                  10.624294              1.823687   \n",
       "4628981                                  10.625399              1.838073   \n",
       "4628982                                  10.627472              1.831767   \n",
       "4628983                                  10.627515              1.829526   \n",
       "\n",
       "         kl_divergence_after  kl_divergence_after_frozen_unigram  \\\n",
       "252                 1.843612                            3.498574   \n",
       "253                 1.838241                            3.497475   \n",
       "254                 1.831377                            3.478915   \n",
       "255                 1.832879                            3.483268   \n",
       "256                 1.842607                            3.492335   \n",
       "...                      ...                                 ...   \n",
       "4628979             1.830017                            3.477201   \n",
       "4628980             1.823684                            3.480128   \n",
       "4628981             1.838057                            3.488969   \n",
       "4628982             1.831775                            3.476626   \n",
       "4628983             1.829497                            3.481569   \n",
       "\n",
       "         ablation_mode  longtail_threshold num_longtail_tokens  \n",
       "252           longtail            0.000003             25152.0  \n",
       "253           longtail            0.000003             25152.0  \n",
       "254           longtail            0.000003             25152.0  \n",
       "255           longtail            0.000003             25152.0  \n",
       "256           longtail            0.000003             25152.0  \n",
       "...                ...                 ...                 ...  \n",
       "4628979       longtail            0.000003             25152.0  \n",
       "4628980       longtail            0.000003             25152.0  \n",
       "4628981       longtail            0.000003             25152.0  \n",
       "4628982       longtail            0.000003             25152.0  \n",
       "4628983       longtail            0.000003             25152.0  \n",
       "\n",
       "[2512 rows x 30 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['component_name']==\"5.1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/jliu/workspace/RAG/results/ablations/longtail/EleutherAI/pythia-70m-deduped/10000/500/k10.feather'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m ckpt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m10000\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m feather_path \u001b[38;5;241m=\u001b[39m ablation_path\u001b[38;5;241m/\u001b[39mvector \u001b[38;5;241m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEleutherAI\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpythia-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-deduped\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m/\u001b[39mckpt \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m500\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk10.feather\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_feather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeather_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/neuron/lib/python3.9/site-packages/pandas/io/feather_format.py:144\u001b[0m, in \u001b[0;36mread_feather\u001b[0;34m(path, columns, use_threads, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m feather\n\u001b[1;32m    142\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m--> 144\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    146\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m feather\u001b[38;5;241m.\u001b[39mread_feather(\n\u001b[1;32m    149\u001b[0m             handles\u001b[38;5;241m.\u001b[39mhandle, columns\u001b[38;5;241m=\u001b[39mcolumns, use_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m(use_threads)\n\u001b[1;32m    150\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/neuron/lib/python3.9/site-packages/pandas/io/common.py:868\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    869\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    871\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/jliu/workspace/RAG/results/ablations/longtail/EleutherAI/pythia-70m-deduped/10000/500/k10.feather'"
     ]
    }
   ],
   "source": [
    "vector = \"longtail\"\n",
    "model = \"70m\"\n",
    "ckpt = \"10000\"\n",
    "feather_path = ablation_path/vector /\"EleutherAI\"/f\"pythia-{model}-deduped\"/ckpt / \"500\" / \"k10.feather\"\n",
    "data = pd.read_feather(feather_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat = (0,0.1)\n",
    "type(stat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'str_tokens', 'unique_token', 'context', 'batch', 'pos',\n",
       "       'label', 'token_id', 'entropy', 'top_logit', 'pred', 'loss', 'top_logp',\n",
       "       'ln_final_scale', 'rank_of_correct_token', 'correct_token_rank',\n",
       "       'pred_in_top1', 'pred_in_top5', 'activation', 'component_name',\n",
       "       'loss_post_ablation', 'loss_post_ablation_with_frozen_unigram',\n",
       "       'entropy_post_ablation', 'entropy_post_ablation_with_frozen_unigram',\n",
       "       'kl_divergence_before', 'kl_divergence_after',\n",
       "       'kl_divergence_after_frozen_unigram', 'ablation_mode',\n",
       "       'longtail_threshold', 'num_longtail_tokens'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.5936679e-07"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"activation\"]<0][\"activation\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_df = data.head(100)\n",
    "sel_df.to_csv(\"sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "effect = \"suppress\"\n",
    "\n",
    "final_df = pd.read_feather(feather_path)\n",
    "final_df[\"abs_delta_loss_post_ablation\"] = np.abs(final_df[\"loss_post_ablation\"] - final_df[\"loss\"])\n",
    "final_df[\"abs_delta_loss_post_ablation_with_frozen_unigram\"] = np.abs(\n",
    "    final_df[\"loss_post_ablation_with_frozen_unigram\"] - final_df[\"loss\"]\n",
    ")\n",
    "final_df[\"delta_loss_post_ablation\"] = final_df[\"loss_post_ablation\"] - final_df[\"loss\"]\n",
    "final_df[\"delta_loss_post_ablation_with_frozen_unigram\"] = final_df[\"loss_post_ablation_with_frozen_unigram\"] - final_df[\"loss\"]\n",
    "\n",
    "if \"kl_divergence_before\" in final_df.columns:\n",
    "    final_df[\"kl_from_unigram_diff\"] = final_df[\"kl_divergence_after\"] - final_df[\"kl_divergence_before\"]\n",
    "    final_df[\"abs_kl_from_unigram_diff\"] = np.abs(final_df[\"kl_divergence_after\"] - final_df[\"kl_divergence_before\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5144576"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_df1 = final_df[final_df[\"kl_from_unigram_diff\"] < 0]\n",
    "\n",
    "final_df2 = final_df[final_df[\"kl_from_unigram_diff\"] > 0]\n",
    "\n",
    "\n",
    "final_df3 = final_df[final_df[\"kl_from_unigram_diff\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011341"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5144576"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df2.shape[0] + final_df1.shape[0] + final_df3.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df1 [\"kl_from_unigram_diff\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the group selction cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def load_search_state(cache_dir: Path, method: str):\n",
    "    \"\"\"Load a search state from a pickle file.\"\"\"\n",
    "    path = cache_dir / f\"{method}_search_state.pkl\"\n",
    "    print(path)\n",
    "    if not path.exists():\n",
    "        print(f\"No state file found for method {method}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        with open(path, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading pickle file for {method}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = Path(\"/Users/jliu/workspace/RAG/results/selection/143000\")\n",
    "method = \"progressive_beam\"\n",
    "\n",
    "def get_search_state(cache_dir, method)->dict:\n",
    "    result = load_search_state(cache_dir, method)\n",
    "    if result[\"completed\"]:\n",
    "        return [result[\"best_result\"],result[\"target_size_result\"]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import typing as t\n",
    "from pathlib import Path\n",
    "\n",
    "T = t.TypeVar('T')\n",
    "\n",
    "\n",
    "class SearchStateManager:\n",
    "    \"\"\"Manages loading and processing of search state data.\"\"\"\n",
    "    \n",
    "    def __init__(self, cache_dir: Path):\n",
    "        \"\"\"Initialize the SearchStateManager with a cache directory.\"\"\"\n",
    "        self.cache_dir = cache_dir\n",
    "    \n",
    "    def load_search_state(self, method: str) -> dict | None:\n",
    "        \"\"\"Load a search state from a pickle file.\"\"\"\n",
    "        path = self.cache_dir / f\"{method}_search_state.pkl\"\n",
    "       \n",
    "        if not path.exists():\n",
    "            print(f\"No state file found for method {method}\")\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            with open(path, \"rb\") as f:\n",
    "                return pickle.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading pickle file for {method}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_search_state(self, method: str) -> list[dict] | None:\n",
    "        \"\"\"Get the best and target size results for a method.\"\"\"\n",
    "        result = self.load_search_state(method)\n",
    "        if result and result.get(\"completed\"):\n",
    "            return [result[\"best_result\"], result[\"target_size_result\"]]\n",
    "        return None\n",
    "    \n",
    "    def get_all_states(self, method_lst: list[str]) -> dict[str, list[dict]]:\n",
    "        \"\"\"Get search states for multiple methods.\"\"\"\n",
    "        state_all = {}\n",
    "        for method in method_lst:\n",
    "            state = self.get_search_state(method)\n",
    "            if state:\n",
    "                state_all[method] = state\n",
    "        return state_all\n",
    "    \n",
    "    def get_best_result(self, results: dict[str, list[dict]], maximize: bool = False) -> dict:\n",
    "        \"\"\"Get the best method and its results based on delta_loss.\"\"\"\n",
    "        if not results:\n",
    "            raise ValueError(\"No valid results to compare\")\n",
    "            \n",
    "        # Comparison function based on maximization goal\n",
    "        if maximize:\n",
    "            best_method_name = max(results.keys(), key=lambda x: results[x][0][\"delta_loss\"])\n",
    "            target_method_name = max(results.keys(), key=lambda x: results[x][1][\"delta_loss\"])\n",
    "        else:\n",
    "            best_method_name = min(results.keys(), key=lambda x: results[x][0][\"delta_loss\"])\n",
    "            target_method_name = min(results.keys(), key=lambda x: results[x][1][\"delta_loss\"])\n",
    "        return {\n",
    "            \"best\": results[best_method_name][0],\n",
    "            \"target_size\": results[target_method_name][1],\n",
    "            \"total\": results\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jliu/workspace/RAG/results/selection/143000/progressive_beam_search_state.pkl\n",
      "/Users/jliu/workspace/RAG/results/selection/143000/hierarchical_cluster_search_state.pkl\n",
      "/Users/jliu/workspace/RAG/results/selection/143000/iterative_pruning_search_state.pkl\n",
      "/Users/jliu/workspace/RAG/results/selection/143000/importance_weighted_search_state.pkl\n",
      "/Users/jliu/workspace/RAG/results/selection/143000/hybrid_search_state.pkl\n"
     ]
    }
   ],
   "source": [
    "# loop and get the whole state\n",
    "cache_dir = Path(\"/Users/jliu/workspace/RAG/results/selection/143000\")\n",
    "method = \"progressive_beam\"\n",
    "method_lst = [\"progressive_beam\",\"hierarchical_cluster\",\"iterative_pruning\",\"importance_weighted\",\"hybrid\"]\n",
    "\n",
    "def load_search_state(cache_dir: Path, method: str):\n",
    "    \"\"\"Load a search state from a pickle file.\"\"\"\n",
    "    path = cache_dir / f\"{method}_search_state.pkl\"\n",
    "    print(path)\n",
    "    if not path.exists():\n",
    "        print(f\"No state file found for method {method}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        with open(path, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading pickle file for {method}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_search_state(cache_dir, method)->dict:\n",
    "    result = load_search_state(cache_dir, method)\n",
    "    if result[\"completed\"]:\n",
    "        return [result[\"best_result\"],result[\"target_size_result\"]]\n",
    "\n",
    "def get_all_states(method_lst):\n",
    "    state_all = {}\n",
    "    for method in method_lst:\n",
    "        state_all[method] = get_search_state(cache_dir, method)\n",
    "    return state_all\n",
    "\n",
    "# get the best results\n",
    "def get_best_result(results,maximize) -> dict:\n",
    "    \"\"\"Run all methods and return the best method and its results.\"\"\"\n",
    "    # Comparison function based on maximization goal\n",
    "    if maximize:\n",
    "        best_method_name = max(results.keys(), key=lambda x: results[x][0][\"delta_loss\"])\n",
    "        target_method_name = max(results.keys(), key=lambda x: results[x][1][\"delta_loss\"])\n",
    "    else:\n",
    "        best_method_name = min(results.keys(), key=lambda x: results[x][0][\"delta_loss\"])\n",
    "        target_method_name = min(results.keys(), key=lambda x: results[x][1][\"delta_loss\"])\n",
    "\n",
    "    return {\"best\": results[best_method_name][0], \"target_size\": results[target_method_name][1], \"total\": results}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the best results\n",
    "def get_best_result(results,maximize) -> dict:\n",
    "    \"\"\"Run all methods and return the best method and its results.\"\"\"\n",
    "    # Comparison function based on maximization goal\n",
    "    if maximize:\n",
    "        best_method_name = max(results.keys(), key=lambda x: results[x][0][\"delta_loss\"])\n",
    "        target_method_name = max(results.keys(), key=lambda x: results[x][1][\"delta_loss\"])\n",
    "    else:\n",
    "        best_method_name = min(results.keys(), key=lambda x: results[x][0][\"delta_loss\"])\n",
    "        target_method_name = min(results.keys(), key=lambda x: results[x][1][\"delta_loss\"])\n",
    "\n",
    "    return {\"best\": results[best_method_name][0], \"target_size\": results[target_method_name][1], \"total\": results}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best': {'neurons': [251, 158],\n",
       "  'delta_loss': -0.0016726985561893127,\n",
       "  'is_target_size': False},\n",
       " 'target_size': {'neurons': [2016,\n",
       "   1991,\n",
       "   1104,\n",
       "   1905,\n",
       "   114,\n",
       "   529,\n",
       "   1429,\n",
       "   1462,\n",
       "   251,\n",
       "   158],\n",
       "  'delta_loss': -0.004507535035376882,\n",
       "  'is_target_size': True},\n",
       " 'total': {'progressive_beam': [{'neurons': [251, 158],\n",
       "    'delta_loss': -0.0016726985561893127,\n",
       "    'is_target_size': False},\n",
       "   {'neurons': [2016, 1991, 1104, 1905, 114, 529, 1429, 1462, 251, 158],\n",
       "    'delta_loss': -0.004507535035376882,\n",
       "    'is_target_size': True}],\n",
       "  'hierarchical_cluster': [{'neurons': [1429,\n",
       "     2016,\n",
       "     1991,\n",
       "     1905,\n",
       "     158,\n",
       "     529,\n",
       "     1462,\n",
       "     114,\n",
       "     251],\n",
       "    'delta_loss': -0.004522155400794753,\n",
       "    'is_target_size': False},\n",
       "   {'neurons': [1429, 2016, 1991, 1905, 158, 529, 1462, 114, 251, 1104],\n",
       "    'delta_loss': -0.004548933999198111,\n",
       "    'is_target_size': True}],\n",
       "  'iterative_pruning': [{'neurons': [2016,\n",
       "     1991,\n",
       "     158,\n",
       "     114,\n",
       "     1905,\n",
       "     1462,\n",
       "     251,\n",
       "     529,\n",
       "     1429,\n",
       "     1104],\n",
       "    'delta_loss': -0.004600633562249832,\n",
       "    'is_target_size': False},\n",
       "   {'neurons': [2016, 1991, 158, 114, 1905, 1462, 251, 529, 1429, 1104],\n",
       "    'delta_loss': -0.004661597726001348,\n",
       "    'is_target_size': True}],\n",
       "  'importance_weighted': [{'neurons': [2016,\n",
       "     1991,\n",
       "     158,\n",
       "     114,\n",
       "     1905,\n",
       "     1462,\n",
       "     251,\n",
       "     529,\n",
       "     1429,\n",
       "     1104],\n",
       "    'delta_loss': -0.0047269370300671515,\n",
       "    'is_target_size': False},\n",
       "   {'neurons': [2016, 1991, 158, 114, 1905, 1462, 251, 529, 1429, 1104],\n",
       "    'delta_loss': -0.0047269370300671515,\n",
       "    'is_target_size': True}],\n",
       "  'hybrid': [{'neurons': [2016, 114, 1429, 158],\n",
       "    'delta_loss': -0.006744582085792637,\n",
       "    'is_target_size': False},\n",
       "   {'neurons': [2016, 1991, 1905, 114, 529, 1429, 1462, 251, 158],\n",
       "    'delta_loss': -0.007105353706441651,\n",
       "    'is_target_size': True}]}}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_result(state_all,maximize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-7.130773610697361e-06,\n",
       " -7.038608600851148e-06,\n",
       " -4.76986951980507e-06,\n",
       " -1.4116523743723519e-05,\n",
       " -5.648876140185166e-06,\n",
       " -3.520868267514743e-05,\n",
       " -3.3175299449794693e-06,\n",
       " -4.951208666170714e-06,\n",
       " -1.767237154126633e-05,\n",
       " -3.821765403699828e-06]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>str_tokens</th>\n",
       "      <th>unique_token</th>\n",
       "      <th>context</th>\n",
       "      <th>batch</th>\n",
       "      <th>pos</th>\n",
       "      <th>label</th>\n",
       "      <th>token_id</th>\n",
       "      <th>entropy</th>\n",
       "      <th>top_logit</th>\n",
       "      <th>...</th>\n",
       "      <th>loss_post_ablation_with_frozen_unigram</th>\n",
       "      <th>entropy_post_ablation</th>\n",
       "      <th>entropy_post_ablation_with_frozen_unigram</th>\n",
       "      <th>kl_divergence_before</th>\n",
       "      <th>kl_divergence_after</th>\n",
       "      <th>kl_divergence_after_frozen_unigram</th>\n",
       "      <th>ablation_mode</th>\n",
       "      <th>longtail_threshold</th>\n",
       "      <th>num_longtail_tokens</th>\n",
       "      <th>diff_loss_frozen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8707</td>\n",
       "      <td>’</td>\n",
       "      <td>’/3</td>\n",
       "      <td>&lt;|endoftext|&gt; support Amazon|’|s</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>34/3</td>\n",
       "      <td>457</td>\n",
       "      <td>0.916765</td>\n",
       "      <td>16.608845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091855</td>\n",
       "      <td>0.916760</td>\n",
       "      <td>0.916760</td>\n",
       "      <td>4.790050</td>\n",
       "      <td>4.790049</td>\n",
       "      <td>9.990311e+09</td>\n",
       "      <td>longtail</td>\n",
       "      <td>9.445668e-07</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>-6.556511e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8708</td>\n",
       "      <td>s</td>\n",
       "      <td>s/4</td>\n",
       "      <td>&lt;|endoftext|&gt; support Amazon’|s| arrival</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>34/4</td>\n",
       "      <td>84</td>\n",
       "      <td>7.373738</td>\n",
       "      <td>12.153364</td>\n",
       "      <td>...</td>\n",
       "      <td>9.126356</td>\n",
       "      <td>7.373729</td>\n",
       "      <td>7.373730</td>\n",
       "      <td>3.420141</td>\n",
       "      <td>3.420139</td>\n",
       "      <td>9.990311e+09</td>\n",
       "      <td>longtail</td>\n",
       "      <td>9.445668e-07</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>-1.907349e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8709</td>\n",
       "      <td>arrival</td>\n",
       "      <td>arrival/5</td>\n",
       "      <td>&lt;|endoftext|&gt; support Amazon’s| arrival|,</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>34/5</td>\n",
       "      <td>13024</td>\n",
       "      <td>4.471160</td>\n",
       "      <td>14.695408</td>\n",
       "      <td>...</td>\n",
       "      <td>2.422079</td>\n",
       "      <td>4.471157</td>\n",
       "      <td>4.471158</td>\n",
       "      <td>2.991667</td>\n",
       "      <td>2.991667</td>\n",
       "      <td>9.990311e+09</td>\n",
       "      <td>longtail</td>\n",
       "      <td>9.445668e-07</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>-2.384186e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8710</td>\n",
       "      <td>,</td>\n",
       "      <td>,/6</td>\n",
       "      <td>support Amazon’s arrival|,| several</td>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>34/6</td>\n",
       "      <td>13</td>\n",
       "      <td>5.708200</td>\n",
       "      <td>14.091806</td>\n",
       "      <td>...</td>\n",
       "      <td>7.784938</td>\n",
       "      <td>5.708184</td>\n",
       "      <td>5.708185</td>\n",
       "      <td>3.667704</td>\n",
       "      <td>3.667702</td>\n",
       "      <td>9.990311e+09</td>\n",
       "      <td>longtail</td>\n",
       "      <td>9.445668e-07</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>-2.384186e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8711</td>\n",
       "      <td>several</td>\n",
       "      <td>several/7</td>\n",
       "      <td>Amazon’s arrival,| several| surveys</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>34/7</td>\n",
       "      <td>2067</td>\n",
       "      <td>6.886786</td>\n",
       "      <td>12.835464</td>\n",
       "      <td>...</td>\n",
       "      <td>8.572117</td>\n",
       "      <td>6.886886</td>\n",
       "      <td>6.886879</td>\n",
       "      <td>3.310757</td>\n",
       "      <td>3.310778</td>\n",
       "      <td>9.990311e+09</td>\n",
       "      <td>longtail</td>\n",
       "      <td>9.445668e-07</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>2.193451e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8712</td>\n",
       "      <td>surveys</td>\n",
       "      <td>surveys/8</td>\n",
       "      <td>’s arrival, several| surveys| have</td>\n",
       "      <td>34</td>\n",
       "      <td>8</td>\n",
       "      <td>34/8</td>\n",
       "      <td>17276</td>\n",
       "      <td>4.310981</td>\n",
       "      <td>16.292671</td>\n",
       "      <td>...</td>\n",
       "      <td>1.798479</td>\n",
       "      <td>4.310988</td>\n",
       "      <td>4.310988</td>\n",
       "      <td>3.779734</td>\n",
       "      <td>3.779734</td>\n",
       "      <td>9.990311e+09</td>\n",
       "      <td>longtail</td>\n",
       "      <td>9.445668e-07</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>8.344650e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8713</td>\n",
       "      <td>have</td>\n",
       "      <td>have/9</td>\n",
       "      <td>s arrival, several surveys| have| found</td>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>34/9</td>\n",
       "      <td>452</td>\n",
       "      <td>4.383304</td>\n",
       "      <td>17.071587</td>\n",
       "      <td>...</td>\n",
       "      <td>2.388429</td>\n",
       "      <td>4.383301</td>\n",
       "      <td>4.383301</td>\n",
       "      <td>5.107384</td>\n",
       "      <td>5.107384</td>\n",
       "      <td>9.990311e+09</td>\n",
       "      <td>longtail</td>\n",
       "      <td>9.445668e-07</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>-2.384186e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8714</td>\n",
       "      <td>found</td>\n",
       "      <td>found/10</td>\n",
       "      <td>arrival, several surveys have| found|.</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>34/10</td>\n",
       "      <td>1119</td>\n",
       "      <td>4.619333</td>\n",
       "      <td>15.078238</td>\n",
       "      <td>...</td>\n",
       "      <td>3.841269</td>\n",
       "      <td>4.619370</td>\n",
       "      <td>4.619363</td>\n",
       "      <td>3.190870</td>\n",
       "      <td>3.190871</td>\n",
       "      <td>9.990311e+09</td>\n",
       "      <td>longtail</td>\n",
       "      <td>9.445668e-07</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>3.337860e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8715</td>\n",
       "      <td>.</td>\n",
       "      <td>./11</td>\n",
       "      <td>, several surveys have found|.| Business</td>\n",
       "      <td>34</td>\n",
       "      <td>11</td>\n",
       "      <td>34/11</td>\n",
       "      <td>15</td>\n",
       "      <td>4.389691</td>\n",
       "      <td>14.009556</td>\n",
       "      <td>...</td>\n",
       "      <td>10.034325</td>\n",
       "      <td>4.389685</td>\n",
       "      <td>4.389686</td>\n",
       "      <td>3.516019</td>\n",
       "      <td>3.516018</td>\n",
       "      <td>9.990311e+09</td>\n",
       "      <td>longtail</td>\n",
       "      <td>9.445668e-07</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8716</td>\n",
       "      <td>Business</td>\n",
       "      <td>Business/12</td>\n",
       "      <td>several surveys have found.| Business| organi...</td>\n",
       "      <td>34</td>\n",
       "      <td>12</td>\n",
       "      <td>34/12</td>\n",
       "      <td>10518</td>\n",
       "      <td>4.128812</td>\n",
       "      <td>15.715575</td>\n",
       "      <td>...</td>\n",
       "      <td>6.508544</td>\n",
       "      <td>4.128804</td>\n",
       "      <td>4.128805</td>\n",
       "      <td>3.807681</td>\n",
       "      <td>3.807680</td>\n",
       "      <td>9.990311e+09</td>\n",
       "      <td>longtail</td>\n",
       "      <td>9.445668e-07</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index str_tokens  unique_token  \\\n",
       "0   8707          ’           ’/3   \n",
       "1   8708          s           s/4   \n",
       "2   8709    arrival     arrival/5   \n",
       "3   8710          ,           ,/6   \n",
       "4   8711    several     several/7   \n",
       "5   8712    surveys     surveys/8   \n",
       "6   8713       have        have/9   \n",
       "7   8714      found      found/10   \n",
       "8   8715          .          ./11   \n",
       "9   8716   Business   Business/12   \n",
       "\n",
       "                                             context  batch  pos  label  \\\n",
       "0                   <|endoftext|> support Amazon|’|s     34    3   34/3   \n",
       "1           <|endoftext|> support Amazon’|s| arrival     34    4   34/4   \n",
       "2          <|endoftext|> support Amazon’s| arrival|,     34    5   34/5   \n",
       "3                support Amazon’s arrival|,| several     34    6   34/6   \n",
       "4                Amazon’s arrival,| several| surveys     34    7   34/7   \n",
       "5                 ’s arrival, several| surveys| have     34    8   34/8   \n",
       "6            s arrival, several surveys| have| found     34    9   34/9   \n",
       "7             arrival, several surveys have| found|.     34   10  34/10   \n",
       "8           , several surveys have found|.| Business     34   11  34/11   \n",
       "9   several surveys have found.| Business| organi...     34   12  34/12   \n",
       "\n",
       "   token_id   entropy  top_logit  ...  loss_post_ablation_with_frozen_unigram  \\\n",
       "0       457  0.916765  16.608845  ...                                0.091855   \n",
       "1        84  7.373738  12.153364  ...                                9.126356   \n",
       "2     13024  4.471160  14.695408  ...                                2.422079   \n",
       "3        13  5.708200  14.091806  ...                                7.784938   \n",
       "4      2067  6.886786  12.835464  ...                                8.572117   \n",
       "5     17276  4.310981  16.292671  ...                                1.798479   \n",
       "6       452  4.383304  17.071587  ...                                2.388429   \n",
       "7      1119  4.619333  15.078238  ...                                3.841269   \n",
       "8        15  4.389691  14.009556  ...                               10.034325   \n",
       "9     10518  4.128812  15.715575  ...                                6.508544   \n",
       "\n",
       "   entropy_post_ablation  entropy_post_ablation_with_frozen_unigram  \\\n",
       "0               0.916760                                   0.916760   \n",
       "1               7.373729                                   7.373730   \n",
       "2               4.471157                                   4.471158   \n",
       "3               5.708184                                   5.708185   \n",
       "4               6.886886                                   6.886879   \n",
       "5               4.310988                                   4.310988   \n",
       "6               4.383301                                   4.383301   \n",
       "7               4.619370                                   4.619363   \n",
       "8               4.389685                                   4.389686   \n",
       "9               4.128804                                   4.128805   \n",
       "\n",
       "   kl_divergence_before  kl_divergence_after  \\\n",
       "0              4.790050             4.790049   \n",
       "1              3.420141             3.420139   \n",
       "2              2.991667             2.991667   \n",
       "3              3.667704             3.667702   \n",
       "4              3.310757             3.310778   \n",
       "5              3.779734             3.779734   \n",
       "6              5.107384             5.107384   \n",
       "7              3.190870             3.190871   \n",
       "8              3.516019             3.516018   \n",
       "9              3.807681             3.807680   \n",
       "\n",
       "   kl_divergence_after_frozen_unigram  ablation_mode  longtail_threshold  \\\n",
       "0                        9.990311e+09       longtail        9.445668e-07   \n",
       "1                        9.990311e+09       longtail        9.445668e-07   \n",
       "2                        9.990311e+09       longtail        9.445668e-07   \n",
       "3                        9.990311e+09       longtail        9.445668e-07   \n",
       "4                        9.990311e+09       longtail        9.445668e-07   \n",
       "5                        9.990311e+09       longtail        9.445668e-07   \n",
       "6                        9.990311e+09       longtail        9.445668e-07   \n",
       "7                        9.990311e+09       longtail        9.445668e-07   \n",
       "8                        9.990311e+09       longtail        9.445668e-07   \n",
       "9                        9.990311e+09       longtail        9.445668e-07   \n",
       "\n",
       "   num_longtail_tokens diff_loss_frozen  \n",
       "0               2240.0    -6.556511e-07  \n",
       "1               2240.0    -1.907349e-06  \n",
       "2               2240.0    -2.384186e-07  \n",
       "3               2240.0    -2.384186e-06  \n",
       "4               2240.0     2.193451e-05  \n",
       "5               2240.0     8.344650e-07  \n",
       "6               2240.0    -2.384186e-07  \n",
       "7               2240.0     3.337860e-06  \n",
       "8               2240.0    -9.536743e-07  \n",
       "9               2240.0    -9.536743e-07  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(final_df[\"diff_loss_frozen\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean(med_lst):\n",
    "    # convert the input string into a list\n",
    "    med_lst = ast.literal_eval(med_lst)\n",
    "    return sum(med_lst)/len(med_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean(neuron_num,model,vec,neuron_type):\n",
    "    neuron_file = neuron_path / neuron_type/vec/\"EleutherAI\"/f\"pythia-{model}-deduped\" / f\"500_{neuron_num}.csv\"\n",
    "    data = pd.read_csv(neuron_file)\n",
    "    data[\"mean_med\"] = data[\"med_effect\"].apply(get_mean)\n",
    "    return set(data[\"mean_med\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longtail:boost:70m:10:{1.0}\n",
      "longtail:boost:70m:50:{1.0}\n",
      "longtail:boost:70m:500:{1.0}\n",
      "longtail:boost:410m:10:{1.0}\n",
      "longtail:boost:410m:50:{1.0}\n",
      "longtail:boost:410m:500:{1.0}\n",
      "longtail:suppress:70m:10:{1.0}\n",
      "longtail:suppress:70m:50:{1.0}\n",
      "longtail:suppress:70m:500:{1.0}\n",
      "longtail:suppress:410m:10:{1.0}\n",
      "longtail:suppress:410m:50:{1.0}\n",
      "longtail:suppress:410m:500:{1.0}\n",
      "mean:boost:70m:10:{1.0}\n",
      "mean:boost:70m:50:{1.0}\n",
      "mean:boost:70m:500:{1.0}\n",
      "mean:boost:410m:10:{1.0}\n",
      "mean:boost:410m:50:{1.0}\n",
      "mean:boost:410m:500:{1.0}\n",
      "mean:suppress:70m:10:{1.0}\n",
      "mean:suppress:70m:50:{1.0}\n",
      "mean:suppress:70m:500:{1.0}\n",
      "mean:suppress:410m:10:{1.0}\n",
      "mean:suppress:410m:50:{1.0}\n",
      "mean:suppress:410m:500:{1.0}\n"
     ]
    }
   ],
   "source": [
    "neuron_name = [10,50,500]\n",
    "models = [\"70m\",\"410m\"]\n",
    "vecs = [\"longtail\",\"mean\"]\n",
    "neuron_types = [\"boost\",\"suppress\"]\n",
    "for vec in vecs:\n",
    "    for neuron_type in neuron_types:\n",
    "        for model in models:\n",
    "            for neuron_num in neuron_name:\n",
    "                print(f\"{vec}:{neuron_type}:{model}:{neuron_num}:{compute_mean(neuron_num,model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>step</th>\n",
       "      <th>top_neurons</th>\n",
       "      <th>med_effect</th>\n",
       "      <th>kl_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>90000</td>\n",
       "      <td>['5.110', '5.96', '5.838', '5.1622', '5.587', ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.001056671142578125, 0.00030994415283203125,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['5.45', '5.1781', '5.1585', '5.1585', '5.1585...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[4.935264587402344e-05, 3.790855407714844e-05,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>40000</td>\n",
       "      <td>['5.189', '5.771', '5.1099', '5.1018', '5.67',...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0013713836669921875, 0.0013532638549804688,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>['5.1585', '5.2037', '5.175', '5.1585', '5.166...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[3.6716461181640625e-05, 3.647804260253906e-05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>91000</td>\n",
       "      <td>['5.1622', '5.1622', '5.1622', '5.1622', '5.16...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.00021791458129882812, 0.00017547607421875, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>41000</td>\n",
       "      <td>['5.1622', '5.1273', '5.1191', '5.1273', '5.11...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.00026988983154296875, 9.822845458984375e-05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>['5.2026', '5.1585', '5.1957', '5.945', '5.158...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[3.9577484130859375e-05, 3.886222839355469e-05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>92000</td>\n",
       "      <td>['5.214', '5.1132', '5.1954', '5.1978', '5.769...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.00029277801513671875, 0.00017547607421875, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>42000</td>\n",
       "      <td>['5.518', '5.1622', '5.1622', '5.1622', '5.147...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.00026702880859375, 0.0001735687255859375, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>['5.1585', '5.1880', '5.1585', '5.1585', '5.15...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[4.267692565917969e-05, 3.743171691894531e-05,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   step                                        top_neurons  \\\n",
       "0           0  90000  ['5.110', '5.96', '5.838', '5.1622', '5.587', ...   \n",
       "1           0      0  ['5.45', '5.1781', '5.1585', '5.1585', '5.1585...   \n",
       "2           0  40000  ['5.189', '5.771', '5.1099', '5.1018', '5.67',...   \n",
       "3           0      1  ['5.1585', '5.2037', '5.175', '5.1585', '5.166...   \n",
       "4           0  91000  ['5.1622', '5.1622', '5.1622', '5.1622', '5.16...   \n",
       "5           0  41000  ['5.1622', '5.1273', '5.1191', '5.1273', '5.11...   \n",
       "6           0      2  ['5.2026', '5.1585', '5.1957', '5.945', '5.158...   \n",
       "7           0  92000  ['5.214', '5.1132', '5.1954', '5.1978', '5.769...   \n",
       "8           0  42000  ['5.518', '5.1622', '5.1622', '5.1622', '5.147...   \n",
       "9           0      4  ['5.1585', '5.1880', '5.1585', '5.1585', '5.15...   \n",
       "\n",
       "                                          med_effect  \\\n",
       "0  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "1  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "2  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "3  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "4  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "5  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "6  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "7  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "8  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "9  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "\n",
       "                                             kl_diff  \n",
       "0  [0.001056671142578125, 0.00030994415283203125,...  \n",
       "1  [4.935264587402344e-05, 3.790855407714844e-05,...  \n",
       "2  [0.0013713836669921875, 0.0013532638549804688,...  \n",
       "3  [3.6716461181640625e-05, 3.647804260253906e-05...  \n",
       "4  [0.00021791458129882812, 0.00017547607421875, ...  \n",
       "5  [0.00026988983154296875, 9.822845458984375e-05...  \n",
       "6  [3.9577484130859375e-05, 3.886222839355469e-05...  \n",
       "7  [0.00029277801513671875, 0.00017547607421875, ...  \n",
       "8  [0.00026702880859375, 0.0001735687255859375, 0...  \n",
       "9  [4.267692565917969e-05, 3.743171691894531e-05,...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>step</th>\n",
       "      <th>top_neurons</th>\n",
       "      <th>med_effect</th>\n",
       "      <th>kl_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>90000</td>\n",
       "      <td>['5.110', '5.96', '5.838', '5.1622', '5.587', ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.001056671142578125, 0.00030994415283203125,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['5.45', '5.1781', '5.1585', '5.1585', '5.1585...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[4.935264587402344e-05, 3.790855407714844e-05,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>40000</td>\n",
       "      <td>['5.189', '5.771', '5.1099', '5.1018', '5.67',...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0013713836669921875, 0.0013532638549804688,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>['5.1585', '5.2037', '5.175', '5.1585', '5.166...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[3.6716461181640625e-05, 3.647804260253906e-05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>91000</td>\n",
       "      <td>['5.1622', '5.1622', '5.1622', '5.1622', '5.16...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.00021791458129882812, 0.00017547607421875, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0</td>\n",
       "      <td>39000</td>\n",
       "      <td>['5.759', '5.1954', '5.1954', '5.1306', '5.147...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0001163482666015625, 8.821487426757812e-05,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0</td>\n",
       "      <td>140000</td>\n",
       "      <td>['5.1174', '5.769', '5.372', '5.587', '5.703',...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.00018262863159179688, 0.000171661376953125,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0</td>\n",
       "      <td>141000</td>\n",
       "      <td>['5.1758', '5.587', '5.769', '5.703', '5.587',...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0002574920654296875, 0.0001983642578125, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0</td>\n",
       "      <td>142000</td>\n",
       "      <td>['5.1263', '5.1529', '5.457', '5.587', '5.50',...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0061244964599609375, 0.0006308555603027344,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0</td>\n",
       "      <td>143000</td>\n",
       "      <td>['5.587', '5.217', '5.1995', '5.703', '5.1756'...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.000270843505859375, 0.0002269744873046875, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0    step                                        top_neurons  \\\n",
       "0             0   90000  ['5.110', '5.96', '5.838', '5.1622', '5.587', ...   \n",
       "1             0       0  ['5.45', '5.1781', '5.1585', '5.1585', '5.1585...   \n",
       "2             0   40000  ['5.189', '5.771', '5.1099', '5.1018', '5.67',...   \n",
       "3             0       1  ['5.1585', '5.2037', '5.175', '5.1585', '5.166...   \n",
       "4             0   91000  ['5.1622', '5.1622', '5.1622', '5.1622', '5.16...   \n",
       "..          ...     ...                                                ...   \n",
       "149           0   39000  ['5.759', '5.1954', '5.1954', '5.1306', '5.147...   \n",
       "150           0  140000  ['5.1174', '5.769', '5.372', '5.587', '5.703',...   \n",
       "151           0  141000  ['5.1758', '5.587', '5.769', '5.703', '5.587',...   \n",
       "152           0  142000  ['5.1263', '5.1529', '5.457', '5.587', '5.50',...   \n",
       "153           0  143000  ['5.587', '5.217', '5.1995', '5.703', '5.1756'...   \n",
       "\n",
       "                                            med_effect  \\\n",
       "0    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "1    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "2    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "3    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "4    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "..                                                 ...   \n",
       "149  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "150  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "151  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "152  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "153  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "\n",
       "                                               kl_diff  \n",
       "0    [0.001056671142578125, 0.00030994415283203125,...  \n",
       "1    [4.935264587402344e-05, 3.790855407714844e-05,...  \n",
       "2    [0.0013713836669921875, 0.0013532638549804688,...  \n",
       "3    [3.6716461181640625e-05, 3.647804260253906e-05...  \n",
       "4    [0.00021791458129882812, 0.00017547607421875, ...  \n",
       "..                                                 ...  \n",
       "149  [0.0001163482666015625, 8.821487426757812e-05,...  \n",
       "150  [0.00018262863159179688, 0.000171661376953125,...  \n",
       "151  [0.0002574920654296875, 0.0001983642578125, 0....  \n",
       "152  [0.0061244964599609375, 0.0006308555603027344,...  \n",
       "153  [0.000270843505859375, 0.0002269744873046875, ...  \n",
       "\n",
       "[154 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"mean_med\"] = data[\"med_effect\"].apply(get_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.0}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(data[\"mean_med\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuron",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
