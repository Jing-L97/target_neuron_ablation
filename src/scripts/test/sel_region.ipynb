{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc07265",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import typing as t\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize, differential_evolution\n",
    "from scipy import stats\n",
    "from dataclasses import dataclass\n",
    "from sklearn.metrics import r2_score\n",
    "import warnings\n",
    "\n",
    "@dataclass\n",
    "class FitResults:\n",
    "    \"\"\"Container for piecewise regression fit results.\"\"\"\n",
    "    r1: float\n",
    "    r2: float\n",
    "    params_regime1: dict[str, float]\n",
    "    params_regime2: dict[str, float] \n",
    "    params_regime3: dict[str, float]\n",
    "    loss_value: float\n",
    "    regime_percentages: dict[int, float]\n",
    "\n",
    "class HuberLoss:\n",
    "    \"\"\"Implements Huber loss function with configurable threshold.\"\"\"\n",
    "    \n",
    "    def __init__(self, tau: float = 1.0):\n",
    "        \"\"\"Initialize Huber loss with threshold parameter.\"\"\"\n",
    "        self.tau = tau\n",
    "    \n",
    "    def __call__(self, residuals: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Compute Huber loss for given residuals.\"\"\"\n",
    "        abs_residuals = np.abs(residuals)\n",
    "        quadratic = abs_residuals <= self.tau\n",
    "        linear = abs_residuals > self.tau\n",
    "        \n",
    "        loss = np.zeros_like(residuals)\n",
    "        loss[quadratic] = 0.5 * residuals[quadratic]**2\n",
    "        loss[linear] = self.tau * (abs_residuals[linear] - 0.5 * self.tau)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def derivative(self, residuals: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Compute derivative of Huber loss for optimization.\"\"\"\n",
    "        abs_residuals = np.abs(residuals)\n",
    "        derivative = np.zeros_like(residuals)\n",
    "        \n",
    "        quadratic = abs_residuals <= self.tau\n",
    "        derivative[quadratic] = residuals[quadratic]\n",
    "        derivative[~quadratic] = self.tau * np.sign(residuals[~quadratic])\n",
    "        \n",
    "        return derivative\n",
    "\n",
    "class PiecewiseRegressor:\n",
    "    \"\"\"Three-regime piecewise regression with Huber loss and continuity constraints.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        tau: float = 1.0,\n",
    "        lambda_cont: float = 1.0,\n",
    "        lambda_delta: float = 0.1\n",
    "    ):\n",
    "        \"\"\"Initialize regressor with hyperparameters.\"\"\"\n",
    "        self.tau = tau\n",
    "        self.lambda_cont = lambda_cont\n",
    "        self.lambda_delta = lambda_delta\n",
    "        self.huber_loss = HuberLoss(tau)\n",
    "        self.fit_results: FitResults | None = None\n",
    "    \n",
    "    def _assign_regimes(self, log_ranks: np.ndarray, r1: float, r2: float) -> np.ndarray:\n",
    "        \"\"\"Assign each data point to its regime (1, 2, or 3).\"\"\"\n",
    "        regimes = np.ones(len(log_ranks), dtype=int)\n",
    "        regimes[log_ranks >= np.log(r1)] = 2\n",
    "        regimes[log_ranks >= np.log(r2)] = 3\n",
    "        return regimes\n",
    "    \n",
    "    def _fit_regime_params(\n",
    "        self, \n",
    "        log_ranks: np.ndarray, \n",
    "        log_values: np.ndarray, \n",
    "        regime_assignments: np.ndarray,\n",
    "        N: int\n",
    "    ) -> tuple[dict, dict, dict]:\n",
    "        \"\"\"Fit parameters for each regime separately.\"\"\"\n",
    "        params = [{}, {}, {}]\n",
    "        \n",
    "        for regime in range(1, 4):\n",
    "            mask = regime_assignments == regime\n",
    "            if not np.any(mask):\n",
    "                # Default parameters if no data in regime\n",
    "                if regime in [1, 2]:\n",
    "                    params[regime-1] = {'a': 0.0, 'b': 0.0}\n",
    "                else:\n",
    "                    params[regime-1] = {'a': 0.0, 'delta': -1.0}\n",
    "                continue\n",
    "                \n",
    "            x_regime = log_ranks[mask]\n",
    "            y_regime = log_values[mask]\n",
    "            \n",
    "            if regime in [1, 2]:\n",
    "                # Linear fit: a + b * log(r)\n",
    "                if len(x_regime) >= 2:\n",
    "                    slope, intercept, _, _, _ = stats.linregress(x_regime, y_regime)\n",
    "                    params[regime-1] = {'a': intercept, 'b': slope}\n",
    "                else:\n",
    "                    # Single point or no variation\n",
    "                    params[regime-1] = {'a': np.mean(y_regime), 'b': 0.0}\n",
    "            else:\n",
    "                # Regime 3: a + delta * log(log(N) - log(r))\n",
    "                log_N = np.log(N)\n",
    "                try:\n",
    "                    # Avoid numerical issues\n",
    "                    valid_mask = x_regime < (log_N - 1e-10)\n",
    "                    if np.any(valid_mask):\n",
    "                        x_transformed = np.log(log_N - x_regime[valid_mask])\n",
    "                        y_transformed = y_regime[valid_mask]\n",
    "                        \n",
    "                        if len(x_transformed) >= 2:\n",
    "                            slope, intercept, _, _, _ = stats.linregress(x_transformed, y_transformed)\n",
    "                            params[regime-1] = {'a': intercept, 'delta': slope}\n",
    "                        else:\n",
    "                            params[regime-1] = {'a': np.mean(y_transformed), 'delta': -1.0}\n",
    "                    else:\n",
    "                        params[regime-1] = {'a': np.mean(y_regime), 'delta': -1.0}\n",
    "                except (ValueError, RuntimeWarning):\n",
    "                    params[regime-1] = {'a': np.mean(y_regime), 'delta': -1.0}\n",
    "        \n",
    "        return params[0], params[1], params[2]\n",
    "    \n",
    "    def _predict_regime(\n",
    "        self, \n",
    "        log_rank: float | np.ndarray, \n",
    "        regime: int, \n",
    "        params: dict[str, float],\n",
    "        N: int\n",
    "    ) -> float | np.ndarray:\n",
    "        \"\"\"Predict value for a single point given regime and parameters.\"\"\"\n",
    "        if regime in [1, 2]:\n",
    "            return params.get('a', 0.0) + params.get('b', 0.0) * log_rank\n",
    "        else:  # regime 3\n",
    "            log_N = np.log(N)\n",
    "            # Avoid numerical issues\n",
    "            safe_log_rank = np.minimum(log_rank, log_N - 1e-10)\n",
    "            return params.get('a', 0.0) + params.get('delta', -1.0) * np.log(log_N - safe_log_rank)\n",
    "    \n",
    "    def _continuity_penalty(\n",
    "        self, \n",
    "        r1: float, \n",
    "        r2: float, \n",
    "        params1: dict, \n",
    "        params2: dict, \n",
    "        params3: dict,\n",
    "        N: int\n",
    "    ) -> float:\n",
    "        \"\"\"Calculate continuity penalty at regime boundaries.\"\"\"\n",
    "        log_r1, log_r2 = np.log(r1), np.log(r2)\n",
    "        \n",
    "        # Continuity at r1\n",
    "        y1_at_r1 = self._predict_regime(log_r1, 1, params1, N)\n",
    "        y2_at_r1 = self._predict_regime(log_r1, 2, params2, N)\n",
    "        penalty_r1 = (y1_at_r1 - y2_at_r1)**2\n",
    "        \n",
    "        # Continuity at r2\n",
    "        y2_at_r2 = self._predict_regime(log_r2, 2, params2, N)\n",
    "        y3_at_r2 = self._predict_regime(log_r2, 3, params3, N)\n",
    "        penalty_r2 = (y2_at_r2 - y3_at_r2)**2\n",
    "        \n",
    "        return penalty_r1 + penalty_r2\n",
    "    \n",
    "    def _objective_function(\n",
    "        self, \n",
    "        boundaries: np.ndarray, \n",
    "        log_ranks: np.ndarray, \n",
    "        log_values: np.ndarray,\n",
    "        N: int\n",
    "    ) -> float:\n",
    "        \"\"\"Main objective function combining Huber loss, continuity, and regularization.\"\"\"\n",
    "        r1, r2 = boundaries\n",
    "        \n",
    "        # Ensure valid boundaries\n",
    "        if r1 <= 1 or r2 <= r1 or r2 >= N:\n",
    "            return 1e10\n",
    "        \n",
    "        # Assign regimes\n",
    "        regime_assignments = self._assign_regimes(log_ranks, r1, r2)\n",
    "        \n",
    "        # Check that each regime has at least some points\n",
    "        unique_regimes = np.unique(regime_assignments)\n",
    "        if len(unique_regimes) < 3:\n",
    "            return 1e10\n",
    "        \n",
    "        # Fit regime parameters\n",
    "        try:\n",
    "            params1, params2, params3 = self._fit_regime_params(\n",
    "                log_ranks, log_values, regime_assignments, N\n",
    "            )\n",
    "            \n",
    "            # Calculate predictions and residuals\n",
    "            predictions = np.zeros_like(log_values)\n",
    "            for i, (log_r, regime) in enumerate(zip(log_ranks, regime_assignments)):\n",
    "                if regime == 1:\n",
    "                    predictions[i] = self._predict_regime(log_r, 1, params1, N)\n",
    "                elif regime == 2:\n",
    "                    predictions[i] = self._predict_regime(log_r, 2, params2, N)\n",
    "                else:\n",
    "                    predictions[i] = self._predict_regime(log_r, 3, params3, N)\n",
    "            \n",
    "            residuals = log_values - predictions\n",
    "            \n",
    "            # Huber loss\n",
    "            huber_loss = np.sum(self.huber_loss(residuals))\n",
    "            \n",
    "            # Continuity penalty\n",
    "            continuity_penalty = self._continuity_penalty(r1, r2, params1, params2, params3, N)\n",
    "            \n",
    "            # Delta regularization\n",
    "            delta_reg = params3.get('delta', 0)**2 if params3 else 0\n",
    "            \n",
    "            total_loss = (huber_loss + \n",
    "                         self.lambda_cont * continuity_penalty + \n",
    "                         self.lambda_delta * delta_reg)\n",
    "            \n",
    "            return total_loss\n",
    "            \n",
    "        except Exception:\n",
    "            return 1e10\n",
    "    \n",
    "    def fit(self, ranks: np.ndarray, delta_loss: np.ndarray) -> FitResults:\n",
    "        \"\"\"Fit the piecewise regression model to data.\"\"\"\n",
    "        # Transform to log space\n",
    "        log_ranks = np.log(ranks)\n",
    "        log_values = np.log(delta_loss)\n",
    "        N = len(ranks)\n",
    "        \n",
    "        # Sort data by rank for proper boundary search\n",
    "        sort_idx = np.argsort(ranks)\n",
    "        ranks_sorted = ranks[sort_idx]\n",
    "        log_ranks_sorted = log_ranks[sort_idx]\n",
    "        log_values_sorted = log_values[sort_idx]\n",
    "        \n",
    "        # Define reasonable bounds for boundary search\n",
    "        min_rank, max_rank = ranks_sorted[5], ranks_sorted[-5]  # Leave some margin\n",
    "        \n",
    "        # Multiple initial guesses for robust optimization\n",
    "        r1_candidates = np.percentile(ranks_sorted, [10, 20, 30])\n",
    "        r2_candidates = np.percentile(ranks_sorted, [60, 70, 80])\n",
    "        \n",
    "        best_loss = float('inf')\n",
    "        best_boundaries = None\n",
    "        \n",
    "        # Try different initialization points\n",
    "        for r1_init in r1_candidates:\n",
    "            for r2_init in r2_candidates:\n",
    "                if r2_init <= r1_init:\n",
    "                    continue\n",
    "                    \n",
    "                # Bounds ensuring r1 < r2 and reasonable separation\n",
    "                bounds = [\n",
    "                    (min_rank, min(r2_init - 1, max_rank * 0.4)),\n",
    "                    (max(r1_init + 1, min_rank * 2), max_rank)\n",
    "                ]\n",
    "                \n",
    "                # Skip if bounds are invalid\n",
    "                if bounds[0][0] >= bounds[0][1] or bounds[1][0] >= bounds[1][1]:\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    with warnings.catch_warnings():\n",
    "                        warnings.simplefilter(\"ignore\")\n",
    "                        \n",
    "                        result = differential_evolution(\n",
    "                            self._objective_function,\n",
    "                            bounds,\n",
    "                            args=(log_ranks_sorted, log_values_sorted, N),\n",
    "                            maxiter=50,\n",
    "                            seed=42,\n",
    "                            atol=1e-6,\n",
    "                            workers=1\n",
    "                        )\n",
    "                    \n",
    "                    if result.fun < best_loss:\n",
    "                        best_loss = result.fun\n",
    "                        best_boundaries = result.x\n",
    "                        \n",
    "                except Exception:\n",
    "                    continue\n",
    "        \n",
    "        if best_boundaries is None:\n",
    "            # Fallback to simple quantile-based boundaries\n",
    "            best_boundaries = [\n",
    "                np.percentile(ranks_sorted, 25),\n",
    "                np.percentile(ranks_sorted, 75)\n",
    "            ]\n",
    "        \n",
    "        # Extract optimal boundaries\n",
    "        r1_opt, r2_opt = best_boundaries\n",
    "        \n",
    "        # Final parameter fitting with optimal boundaries\n",
    "        regime_assignments = self._assign_regimes(log_ranks_sorted, r1_opt, r2_opt)\n",
    "        params1, params2, params3 = self._fit_regime_params(\n",
    "            log_ranks_sorted, log_values_sorted, regime_assignments, N\n",
    "        )\n",
    "        \n",
    "        # Calculate regime percentages\n",
    "        regime_counts = np.bincount(regime_assignments, minlength=4)[1:]\n",
    "        regime_percentages = {\n",
    "            i+1: count/len(regime_assignments)*100 \n",
    "            for i, count in enumerate(regime_counts)\n",
    "        }\n",
    "        \n",
    "        # Store results\n",
    "        self.fit_results = FitResults(\n",
    "            r1=r1_opt,\n",
    "            r2=r2_opt,\n",
    "            params_regime1=params1,\n",
    "            params_regime2=params2,\n",
    "            params_regime3=params3,\n",
    "            loss_value=best_loss,\n",
    "            regime_percentages=regime_percentages\n",
    "        )\n",
    "        \n",
    "        return self.fit_results\n",
    "    \n",
    "    def predict(self, ranks: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Predict values for new rank data using fitted model.\"\"\"\n",
    "        if self.fit_results is None:\n",
    "            raise ValueError(\"Model must be fitted before prediction\")\n",
    "        \n",
    "        log_ranks = np.log(ranks)\n",
    "        N = len(ranks)\n",
    "        regime_assignments = self._assign_regimes(log_ranks, self.fit_results.r1, self.fit_results.r2)\n",
    "        \n",
    "        predictions = np.zeros(len(ranks))\n",
    "        for i, (log_r, regime) in enumerate(zip(log_ranks, regime_assignments)):\n",
    "            if regime == 1:\n",
    "                pred = self._predict_regime(log_r, 1, self.fit_results.params_regime1, N)\n",
    "            elif regime == 2:\n",
    "                pred = self._predict_regime(log_r, 2, self.fit_results.params_regime2, N)\n",
    "            else:\n",
    "                pred = self._predict_regime(log_r, 3, self.fit_results.params_regime3, N)\n",
    "            predictions[i] = pred\n",
    "        \n",
    "        return np.exp(predictions)\n",
    "    \n",
    "    def get_regime_boundaries(self) -> tuple[float, float]:\n",
    "        \"\"\"Get the fitted regime boundaries r1 and r2.\"\"\"\n",
    "        if self.fit_results is None:\n",
    "            raise ValueError(\"Model must be fitted first\")\n",
    "        return self.fit_results.r1, self.fit_results.r2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f5aa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PiecewiseRegressionPlotter:\n",
    "    \"\"\"Visualization tools for piecewise regression results.\"\"\"\n",
    "    \n",
    "    def __init__(self, figsize: tuple[int, int] = (12, 8)):\n",
    "        \"\"\"Initialize plotter with figure configuration.\"\"\"\n",
    "        self.figsize = figsize\n",
    "        self.regime_colors = {'regime1': '#E6E6FA', 'regime2': '#E0FFE0', 'regime3': '#FFE0E0'}\n",
    "        self.line_colors = {'regime1': 'blue', 'regime2': 'green', 'regime3': 'red'}\n",
    "    \n",
    "    def plot_fit_results(\n",
    "        self, \n",
    "        ranks: np.ndarray, \n",
    "        delta_loss: np.ndarray, \n",
    "        fit_results: FitResults,\n",
    "        save_path: Path | None = None\n",
    "    ) -> plt.Figure:\n",
    "        \"\"\"Create main piecewise regression visualization matching the example.\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=self.figsize)\n",
    "        \n",
    "        log_ranks = np.log(ranks)\n",
    "        log_values = np.log(delta_loss)\n",
    "        N = len(ranks)\n",
    "        \n",
    "        # Add regime backgrounds\n",
    "        self._add_regime_backgrounds(ax, log_ranks, fit_results.r1, fit_results.r2)\n",
    "        \n",
    "        # Plot original data points\n",
    "        ax.scatter(log_ranks, log_values, alpha=0.6, s=30, color='steelblue', zorder=3)\n",
    "        \n",
    "        # Generate smooth fitted curve\n",
    "        dense_ranks = np.logspace(np.log10(ranks.min()), np.log10(ranks.max()), 1000)\n",
    "        dense_log_ranks = np.log(dense_ranks)\n",
    "        dense_regime_assignments = self._assign_regimes_array(dense_log_ranks, fit_results.r1, fit_results.r2)\n",
    "        \n",
    "        fitted_values = np.zeros(len(dense_ranks))\n",
    "        for i, (log_r, regime) in enumerate(zip(dense_log_ranks, dense_regime_assignments)):\n",
    "            if regime == 1:\n",
    "                fitted_values[i] = self._predict_single(log_r, 1, fit_results.params_regime1, N)\n",
    "            elif regime == 2:\n",
    "                fitted_values[i] = self._predict_single(log_r, 2, fit_results.params_regime2, N)\n",
    "            else:\n",
    "                fitted_values[i] = self._predict_single(log_r, 3, fit_results.params_regime3, N)\n",
    "        \n",
    "        # Plot fitted curve\n",
    "        ax.plot(dense_log_ranks, fitted_values, color='steelblue', linewidth=2.5, zorder=4)\n",
    "        \n",
    "        # Add boundary markers\n",
    "        log_r1, log_r2 = np.log(fit_results.r1), np.log(fit_results.r2)\n",
    "        \n",
    "        # Find boundary values on curve\n",
    "        r1_val = self._predict_single(log_r1, 1, fit_results.params_regime1, N)\n",
    "        r2_val = self._predict_single(log_r2, 2, fit_results.params_regime2, N)\n",
    "        \n",
    "        ax.plot(log_r1, r1_val, marker='D', markersize=8, color='steelblue', markeredgecolor='white', zorder=5)\n",
    "        ax.plot(log_r2, r2_val, marker='D', markersize=8, color='steelblue', markeredgecolor='white', zorder=5)\n",
    "        \n",
    "        # Add horizontal dashed lines for regime fits\n",
    "        regime1_val = fit_results.params_regime1.get('a', 0)\n",
    "        regime3_val = fit_results.params_regime3.get('a', 0)\n",
    "        \n",
    "        ax.axhline(regime1_val, color='blue', linestyle='--', alpha=0.7, zorder=2)\n",
    "        ax.axhline(regime3_val, color='green', linestyle='--', alpha=0.7, zorder=2)\n",
    "        \n",
    "        # Add regime labels\n",
    "        self._add_regime_labels(ax, fit_results.regime_percentages, fit_results.r1, fit_results.r2, log_ranks)\n",
    "        \n",
    "        # Styling\n",
    "        ax.set_xlabel('Log Rank', fontsize=14)\n",
    "        ax.set_ylabel('Log Value', fontsize=14)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.tick_params(labelsize=12)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            fig.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def plot_residuals(\n",
    "        self, \n",
    "        ranks: np.ndarray, \n",
    "        delta_loss: np.ndarray, \n",
    "        fit_results: FitResults\n",
    "    ) -> plt.Figure:\n",
    "        \"\"\"Plot residual analysis for model diagnostics.\"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # Calculate residuals\n",
    "        regressor = PiecewiseRegressor()\n",
    "        regressor.fit_results = fit_results\n",
    "        predicted = regressor.predict(ranks)\n",
    "        residuals = delta_loss - predicted\n",
    "        \n",
    "        # Residuals vs fitted\n",
    "        ax1.scatter(predicted, residuals, alpha=0.6)\n",
    "        ax1.axhline(0, color='red', linestyle='--')\n",
    "        ax1.set_xlabel('Fitted Values')\n",
    "        ax1.set_ylabel('Residuals')\n",
    "        ax1.set_title('Residuals vs Fitted')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Q-Q plot\n",
    "        stats.probplot(residuals, dist=\"norm\", plot=ax2)\n",
    "        ax2.set_title('Q-Q Plot')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    \n",
    "    def plot_regime_breakdown(self, fit_results: FitResults) -> plt.Figure:\n",
    "        \"\"\"Display statistical breakdown of regime assignments.\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        regimes = list(fit_results.regime_percentages.keys())\n",
    "        percentages = list(fit_results.regime_percentages.values())\n",
    "        colors = [self.line_colors[f'regime{i}'] for i in regimes]\n",
    "        \n",
    "        bars = ax.bar(regimes, percentages, color=colors, alpha=0.7)\n",
    "        \n",
    "        # Add percentage labels on bars\n",
    "        for bar, pct in zip(bars, percentages):\n",
    "            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "                   f'{pct:.1f}%', ha='center', va='bottom', fontsize=12)\n",
    "        \n",
    "        ax.set_xlabel('Regime')\n",
    "        ax.set_ylabel('Percentage of Data Points')\n",
    "        ax.set_title('Data Distribution Across Regimes')\n",
    "        ax.set_xticks(regimes)\n",
    "        ax.set_xticklabels([f'Regime {i}' for i in regimes])\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    \n",
    "    def _add_regime_backgrounds(\n",
    "        self, \n",
    "        ax: plt.Axes, \n",
    "        log_ranks: np.ndarray, \n",
    "        r1: float, \n",
    "        r2: float\n",
    "    ) -> None:\n",
    "        \"\"\"Add colored background regions for each regime.\"\"\"\n",
    "        x_min, x_max = log_ranks.min(), log_ranks.max()\n",
    "        log_r1, log_r2 = np.log(r1), np.log(r2)\n",
    "        \n",
    "        # Regime 1 background\n",
    "        ax.axvspan(x_min, log_r1, alpha=0.2, color='blue', zorder=1)\n",
    "        \n",
    "        # Regime 2 background  \n",
    "        ax.axvspan(log_r1, log_r2, alpha=0.2, color='green', zorder=1)\n",
    "        \n",
    "        # Regime 3 background\n",
    "        ax.axvspan(log_r2, x_max, alpha=0.2, color='red', zorder=1)\n",
    "    \n",
    "    def _add_regime_labels(\n",
    "        self, \n",
    "        ax: plt.Axes, \n",
    "        regime_percentages: dict[int, float],\n",
    "        r1: float, \n",
    "        r2: float,\n",
    "        log_ranks: np.ndarray\n",
    "    ) -> None:\n",
    "        \"\"\"Add percentage labels to each regime region.\"\"\"\n",
    "        x_min, x_max = log_ranks.min(), log_ranks.max()\n",
    "        log_r1, log_r2 = np.log(r1), np.log(r2)\n",
    "        y_min, y_max = ax.get_ylim()\n",
    "        \n",
    "        # Calculate label positions\n",
    "        regime1_center = (x_min + log_r1) / 2\n",
    "        regime2_center = (log_r1 + log_r2) / 2\n",
    "        regime3_center = (log_r2 + x_max) / 2\n",
    "        label_y = y_min + 0.85 * (y_max - y_min)\n",
    "        \n",
    "        # Add labels\n",
    "        colors = ['blue', 'green', 'red']\n",
    "        centers = [regime1_center, regime2_center, regime3_center]\n",
    "        \n",
    "        for i, (center, color) in enumerate(zip(centers, colors)):\n",
    "            pct = regime_percentages.get(i+1, 0)\n",
    "            ax.text(center, label_y, f'{pct:.1f}%', \n",
    "                   ha='center', va='center', fontsize=16, \n",
    "                   color=color, fontweight='bold', zorder=6)\n",
    "    \n",
    "    def _assign_regimes_array(self, log_ranks: np.ndarray, r1: float, r2: float) -> np.ndarray:\n",
    "        \"\"\"Assign regimes for array of log ranks.\"\"\"\n",
    "        regimes = np.ones(len(log_ranks), dtype=int)\n",
    "        regimes[log_ranks >= np.log(r1)] = 2\n",
    "        regimes[log_ranks >= np.log(r2)] = 3\n",
    "        return regimes\n",
    "    \n",
    "    def _predict_single(self, log_rank: float, regime: int, params: dict[str, float], N: int) -> float:\n",
    "        \"\"\"Predict single value for plotting.\"\"\"\n",
    "        if regime in [1, 2]:\n",
    "            return params.get('a', 0.0) + params.get('b', 0.0) * log_rank\n",
    "        else:  # regime 3\n",
    "            log_N = np.log(N)\n",
    "            safe_log_rank = min(log_rank, log_N - 1e-10)\n",
    "            return params.get('a', 0.0) + params.get('delta', -1.0) * np.log(log_N - safe_log_rank)\n",
    "\n",
    "class PiecewiseRegressionPipeline:\n",
    "    \"\"\"High-level pipeline for complete piecewise regression analysis.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        tau: float = 1.0,\n",
    "        lambda_cont: float = 1.0, \n",
    "        lambda_delta: float = 0.1,\n",
    "        figsize: tuple[int, int] = (12, 8)\n",
    "    ):\n",
    "        \"\"\"Initialize pipeline with model and plotting configurations.\"\"\"\n",
    "        self.regressor = PiecewiseRegressor(tau, lambda_cont, lambda_delta)\n",
    "        self.plotter = PiecewiseRegressionPlotter(figsize)\n",
    "    \n",
    "    def run_analysis(\n",
    "        self,\n",
    "        ranks: np.ndarray,\n",
    "        delta_loss: np.ndarray,\n",
    "        output_dir: Path | None = None\n",
    "    ) -> tuple[FitResults, dict[str, plt.Figure]]:\n",
    "        \"\"\"Run complete analysis pipeline with fitting and visualization.\"\"\"\n",
    "        \n",
    "        # Fit the model\n",
    "        print(\"Fitting piecewise regression model...\")\n",
    "        fit_results = self.regressor.fit(ranks, delta_loss)\n",
    "        \n",
    "        # Generate plots\n",
    "        print(\"Generating visualizations...\")\n",
    "        plots = {}\n",
    "        \n",
    "        # Main fit plot\n",
    "        plots['fit'] = self.plotter.plot_fit_results(ranks, delta_loss, fit_results)\n",
    "        \n",
    "        # Residual analysis\n",
    "        plots['residuals'] = self.plotter.plot_residuals(ranks, delta_loss, fit_results)\n",
    "        \n",
    "        # Regime breakdown\n",
    "        plots['breakdown'] = self.plotter.plot_regime_breakdown(fit_results)\n",
    "        \n",
    "        # Save plots if output directory specified\n",
    "        if output_dir:\n",
    "            output_dir = Path(output_dir)\n",
    "            output_dir.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            for name, fig in plots.items():\n",
    "                fig.savefig(output_dir / f'{name}_plot.png', dpi=300, bbox_inches='tight')\n",
    "        \n",
    "        # Print summary\n",
    "        self._print_summary(fit_results)\n",
    "        \n",
    "        return fit_results, plots\n",
    "    \n",
    "    def cross_validate_hyperparameters(\n",
    "        self,\n",
    "        ranks: np.ndarray,\n",
    "        delta_loss: np.ndarray,\n",
    "        param_grid: dict[str, list[float]]\n",
    "    ) -> dict[str, float]:\n",
    "        \"\"\"Cross-validation for hyperparameter selection.\"\"\"\n",
    "        best_loss = float('inf')\n",
    "        best_params = {}\n",
    "        \n",
    "        # Simple grid search\n",
    "        for tau in param_grid.get('tau', [self.regressor.tau]):\n",
    "            for lambda_cont in param_grid.get('lambda_cont', [self.regressor.lambda_cont]):\n",
    "                for lambda_delta in param_grid.get('lambda_delta', [self.regressor.lambda_delta]):\n",
    "                    \n",
    "                    regressor = PiecewiseRegressor(tau, lambda_cont, lambda_delta)\n",
    "                    try:\n",
    "                        results = regressor.fit(ranks, delta_loss)\n",
    "                        if results.loss_value < best_loss:\n",
    "                            best_loss = results.loss_value\n",
    "                            best_params = {'tau': tau, 'lambda_cont': lambda_cont, 'lambda_delta': lambda_delta}\n",
    "                    except Exception:\n",
    "                        continue\n",
    "        \n",
    "        return best_params\n",
    "    \n",
    "    def _print_summary(self, fit_results: FitResults) -> None:\n",
    "        \"\"\"Print summary of fit results.\"\"\"\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(\"PIECEWISE REGRESSION RESULTS\")\n",
    "        print(f\"{'='*50}\")\n",
    "        print(f\"Regime boundaries:\")\n",
    "        print(f\"  r1 = {fit_results.r1:.2f}\")\n",
    "        print(f\"  r2 = {fit_results.r2:.2f}\")\n",
    "        print(f\"\\nRegime percentages:\")\n",
    "        for regime, pct in fit_results.regime_percentages.items():\n",
    "            print(f\"  Regime {regime}: {pct:.1f}%\")\n",
    "        print(f\"\\nFinal loss value: {fit_results.loss_value:.4f}\")\n",
    "        print(f\"{'='*50}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf57e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_analyze_data(data_path: Path) -> tuple[FitResults, dict[str, plt.Figure]]:\n",
    "    \"\"\"Load data from file and run piecewise regression analysis.\"\"\"\n",
    "    \n",
    "    \n",
    "    import pandas as pd\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(data_path)\n",
    "        ranks = df['rank'].values\n",
    "        delta_loss = df['delta_loss'].values\n",
    "        \n",
    "        # Remove any invalid data\n",
    "        valid_mask = (ranks > 0) & (delta_loss > 0) & np.isfinite(ranks) & np.isfinite(delta_loss)\n",
    "        ranks = ranks[valid_mask]\n",
    "        delta_loss = delta_loss[valid_mask]\n",
    "        \n",
    "        # Sort by rank\n",
    "        sort_idx = np.argsort(ranks)\n",
    "        ranks = ranks[sort_idx]\n",
    "        delta_loss = delta_loss[sort_idx]\n",
    "        \n",
    "        print(f\"Loaded {len(ranks)} data points from {data_path}\")\n",
    "        print(f\"Rank range: {ranks.min():.1f} to {ranks.max():.1f}\")\n",
    "        print(f\"Loss range: {delta_loss.min():.2e} to {delta_loss.max():.2e}\")\n",
    "        \n",
    "        # Run analysis\n",
    "        pipeline = PiecewiseRegressionPipeline()\n",
    "        fit_results, plots = pipeline.run_analysis(ranks, delta_loss)\n",
    "        \n",
    "        return fit_results, plots\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7293e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run analysis\n",
    "pipeline = PiecewiseRegressionPipeline(\n",
    "    tau=1.0,\n",
    "    lambda_cont=10.0,  # Higher weight for continuity\n",
    "    lambda_delta=0.1\n",
    ")\n",
    "fit_results, plots = pipeline.run_analysis(ranks, delta_loss)\n",
    "\n",
    "# Compare with true boundaries\n",
    "print(f\"\\nBoundary estimation error:\")\n",
    "print(f\"  r1 error: {abs(fit_results.r1 - true_r1):.2f}\")\n",
    "print(f\"  r2 error: {abs(fit_results.r2 - true_r2):.2f}\")\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
