{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set configs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all the predefined functions\n",
    "from plot_util import SurprisalLoader, SurprisalPlotter, plot_geometry_step, load_kl\n",
    "\n",
    "# plot and save the results\n",
    "neuron_colors = {\n",
    "    0: \"#1f77b4\",  # blue for baseline\n",
    "    1: \"#4589b9\",  # interpolated between 0 and 10\n",
    "    2: \"#6b9bbe\",  # interpolated between 0 and 10\n",
    "    5: \"#a5bec6\",  # interpolated between 0 and 10\n",
    "    10: \"#ff7f0e\",  # orange (unchanged)\n",
    "    25: \"#c89f1d\",  # interpolated between 10 and 50\n",
    "    50: \"#2ca02c\",  # green (unchanged)\n",
    "    500: \"#9467bd\",  # purple (unchanged)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path(\"/Users/jliu/workspace/RAG/\")\n",
    "fig_path = ROOT / \"fig\"\n",
    "surprisal_path = ROOT / \"results\" / \"surprisal\"\n",
    "KL_path = ROOT / \"results\" / \"token_freq\"\n",
    "geometry_path = ROOT / \"results\" / \"directions\" / \"geometry\" / \"EleutherAI\"\n",
    "freq_path = ROOT / \"datasets/freq/EleutherAI/pythia-410m\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surprisal dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class SurprisalPlotter:\n",
    "    \"\"\"Class for plotting model effect data with various filtering options.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        output_dir: Path,\n",
    "        neuron_colors: dict[int, str],\n",
    "        ylim_dict: dict[str, dict[str, tuple[float, float]]],\n",
    "        models=None,\n",
    "        effect_lst=None,\n",
    "        vec_lst=None,\n",
    "        ablations=None,\n",
    "        neurons=None,\n",
    "    ):\n",
    "        \"\"\"Initialize the plotter with data and configuration.\"\"\"\n",
    "        self.df = df\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.neuron_colors = neuron_colors\n",
    "        self.ylim_dict = ylim_dict\n",
    "\n",
    "        # Set models or compute from df if None\n",
    "        self.models = models if models is not None else df[\"model\"].unique().tolist()\n",
    "        self.effect_lst = effect_lst if effect_lst is not None else df[\"effect\"].unique().tolist()\n",
    "        self.vec_lst = vec_lst if vec_lst is not None else df[\"vec\"].unique().tolist()\n",
    "        # Make sure \"base\" is not included in ablations to avoid creating \"base_*.png\" files\n",
    "        if ablations is not None:\n",
    "            self.ablations = [a for a in ablations if a != \"base\"]\n",
    "        else:\n",
    "            self.ablations = [a for a in df[\"ablation\"].unique() if a != \"base\"]\n",
    "        self.neurons = neurons if neurons is not None else df[\"neuron\"].unique().tolist()\n",
    "\n",
    "    def _plot_line(self, data: pd.DataFrame, label: str) -> bool:\n",
    "        \"\"\" Plot a single line for the given data.\"\"\"\n",
    "        if data.empty:\n",
    "            return False\n",
    "\n",
    "        baseline_grouped = data.groupby(\"log_step\")\n",
    "        x_values = sorted(data[\"log_step\"].unique())\n",
    "\n",
    "        # Extract surprisal values\n",
    "        y_values = [\n",
    "            baseline_grouped.get_group(log_step)[\"surprisal\"].values[0]\n",
    "            for log_step in x_values\n",
    "            if log_step in baseline_grouped.groups\n",
    "        ]\n",
    "\n",
    "        if not y_values:  # Skip if no values to plot\n",
    "            return False\n",
    "\n",
    "        # Determine color based on label\n",
    "        if label == \"baseline\":\n",
    "            color = self.neuron_colors.get(0, \"black\")\n",
    "        else:\n",
    "            try:\n",
    "                neuron_id = int(label)\n",
    "                color = self.neuron_colors.get(neuron_id, \"black\")\n",
    "            except ValueError:\n",
    "                color = \"black\"\n",
    "\n",
    "        # Plot the line\n",
    "        plt.plot(x_values, y_values, color=color, linewidth=2, label=label)\n",
    "        return True\n",
    "\n",
    "    def plot_all(self, eval_set: str, figure_size: tuple[int, int] = (10, 8)) -> list[Path]:\n",
    "        \"\"\"Plot the overall development using the configuration from initialization. \"\"\"\n",
    "\n",
    "        # Process each model and ablation type using class attributes\n",
    "        for effect in self.effect_lst:\n",
    "            for vec in self.vec_lst:\n",
    "                for model in self.models:\n",
    "                    for ablation in self.ablations:\n",
    "                        # Create a new figure\n",
    "                        plt.figure(figsize=figure_size)\n",
    "\n",
    "                        # Get baseline data (always include baseline for comparison)\n",
    "                        baseline_data = self.df[\n",
    "                            (self.df[\"model\"] == model)\n",
    "                            & (self.df[\"ablation\"] == \"base\")\n",
    "                            & (self.df[\"eval\"] == eval_set)\n",
    "                            & (self.df[\"effect\"] == effect)\n",
    "                        ]\n",
    "\n",
    "                        # Filter data for this model and configuration\n",
    "                        model_data = self.df[\n",
    "                            (self.df[\"model\"] == model)\n",
    "                            & (self.df[\"vec\"] == vec)\n",
    "                            & (self.df[\"eval\"] == eval_set)\n",
    "                            & (self.df[\"effect\"] == effect)\n",
    "                            & (self.df[\"ablation\"] == ablation)\n",
    "                        ]\n",
    "\n",
    "                        # slice df to have the same log steps  \n",
    "                        # TODO: wrap into a function\n",
    "                        common_steps = set(baseline_data[\"log_step\"]) & set(model_data[\"log_step\"])\n",
    "                        baseline_data = baseline_data[baseline_data[\"log_step\"].isin(common_steps)]\n",
    "                        model_data = model_data[model_data[\"log_step\"].isin(common_steps)]\n",
    "\n",
    "                        # Plot baseline data first\n",
    "                        baseline_plotted = self._plot_line(baseline_data, \"baseline\")\n",
    "\n",
    "                        # Count how many lines we've plotted\n",
    "                        lines_plotted = 1 if baseline_plotted else 0\n",
    "\n",
    "                        if model_data.empty and not baseline_plotted:\n",
    "                            plt.close()\n",
    "                            continue\n",
    "\n",
    "                        # Process each neuron condition for this ablation\n",
    "                        for neuron in self.neurons:\n",
    "                            # Filter data for this neuron and ablation combination\n",
    "                            condition_data = model_data[(model_data[\"neuron\"] == neuron)]\n",
    "\n",
    "                            # Plot neuron data\n",
    "                            if self._plot_line(condition_data, str(neuron)):\n",
    "                                lines_plotted += 1\n",
    "\n",
    "                        # Check if we have any plotted data or if it's a base ablation\n",
    "                        if lines_plotted == 0 or ablation == \"base\":\n",
    "                            plt.close()\n",
    "                            continue\n",
    "\n",
    "                        # Style the plot\n",
    "                        plt.xlabel(\"Log step\", fontsize=12)\n",
    "                        plt.ylabel(\"Surprisal\", fontsize=12)\n",
    "                        plt.title(f\"neuron={effect}, vec={vec}, intervention={ablation}\", fontsize=13)\n",
    "                        plt.grid(alpha=0.2)\n",
    "\n",
    "                        # Create legend with baseline first\n",
    "                        handles, labels = plt.gca().get_legend_handles_labels()\n",
    "\n",
    "                        if handles:  # Only create legend if we have items to show\n",
    "                            # If baseline is in the legend, make sure it comes first\n",
    "                            if \"baseline\" in labels:\n",
    "                                base_idx = labels.index(\"baseline\")\n",
    "                                # Move baseline to front\n",
    "                                handles = [handles[base_idx]] + [h for i, h in enumerate(handles) if i != base_idx]\n",
    "                                labels = [labels[base_idx]] + [l for i, l in enumerate(labels) if i != base_idx]\n",
    "\n",
    "                            plt.legend(handles, labels, loc=\"lower left\")\n",
    "\n",
    "                        # Set y-axis limits if provided\n",
    "                        if eval_set in self.ylim_dict and model in self.ylim_dict[eval_set]:\n",
    "                            plt.ylim(self.ylim_dict[eval_set][model])\n",
    "\n",
    "                        # Save the figure\n",
    "                        plt.tight_layout()\n",
    "\n",
    "                        # Create output directory if it doesn't exist\n",
    "                        output_path = self.output_dir / effect / eval_set\n",
    "                        output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                        # Final check to absolutely make sure we never save any files with \"base\" in the name\n",
    "                        if vec != \"base\":\n",
    "                            output_file = output_path / f\"{vec}_{model}_{ablation}.png\"\n",
    "                            plt.savefig(output_file, dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "                        plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat file has been saved to /Users/jliu/workspace/RAG/results/surprisal/stat_all.csv\n"
     ]
    }
   ],
   "source": [
    "# load file\n",
    "stat_path = surprisal_path / \"stat_all.csv\"\n",
    "resume = False\n",
    "if stat_path.is_file() and resume:\n",
    "    stat_frame = pd.read_csv(stat_path)\n",
    "    print(f\"Load from {stat_path}\")\n",
    "else:\n",
    "    analyzer = SurprisalLoader(surprisal_path)\n",
    "    # Process all files and get statistics\n",
    "    stats = analyzer.get_stat_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylim_dict = {\n",
    "    \"merged\": {\"70m\": [11.5, 15.5], \"410m\": [12.5, 14]},\n",
    "    \"longtail_words\": {\"70m\": [13, 17], \"410m\": [12, 15.5]},\n",
    "}\n",
    "\n",
    "\n",
    "surprisal_plotter = SurprisalPlotter(\n",
    "    df=stats,\n",
    "    output_dir=fig_path/\"surprisal\",\n",
    "    neuron_colors=neuron_colors,\n",
    "    ylim_dict=ylim_dict,\n",
    "    neurons=[10, 50],\n",
    "    ablations=[\"mean\", \"zero\"]\n",
    ")\n",
    "\n",
    "surprisal_plotter.plot_all(eval_set=\"longtail_words\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KL distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot KL difference in differnt conditions\n",
    "effect_lst=[\"boost\",\"suppress\"]\n",
    "vec_lst = [\"mean\",\"longtail\"]\n",
    "model_lst = [\"70m\",\"410m\"]\n",
    "neuron_lst = [10,50,500]\n",
    "\n",
    "stat_frame = pd.DataFrame()\n",
    "for vec in vec_lst:\n",
    "    for model in model_lst:\n",
    "        suffix_path = Path(vec)/\"EleutherAI\"/f\"pythia-{model}-deduped\"\n",
    "        data_dict = {}\n",
    "        for neuron in neuron_lst:\n",
    "            data_dict[neuron] = {}\n",
    "            for effect in effect_lst:\n",
    "                # load file\n",
    "                file_path = KL_path / effect / suffix_path / f\"500_{neuron}.csv\"\n",
    "                kl_lst,stat_df = load_kl(file_path)\n",
    "                data_dict[neuron][effect] = kl_lst\n",
    "                header_dict = {\"vec\":vec,\"model\":model,\"neuron\":neuron,\"effect\":effect}\n",
    "                for header,col in header_dict.items():\n",
    "                    stat_df[header]=col\n",
    "                stat_frame = pd.concat([stat_frame,stat_df])\n",
    "\n",
    "stat_frame.to_csv(KL_path / \"kl_stat.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geometric difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "class GeometryLoader:\n",
    "    \"\"\"Class for loading and processing geometric metric data.\"\"\"\n",
    "\n",
    "    def __init__(self, min_step: float = 3.5):\n",
    "        self.min_step = min_step\n",
    "\n",
    "    @staticmethod\n",
    "    def convert_log(step: float) -> float:\n",
    "        return np.log10(step + 1e-10)\n",
    "\n",
    "    def convert_log_step(self, file_path: Path) -> pd.DataFrame:\n",
    "        # Load the data\n",
    "        data = pd.read_csv(file_path)\n",
    "        # Apply log conversion\n",
    "        data[\"log_step\"] = data[\"step\"].apply(self.convert_log)\n",
    "        # Filter by minimum log step\n",
    "        return data[data[\"log_step\"] > self.min_step].copy()\n",
    "\n",
    "    def load_subspace(self, data: pd.DataFrame, neuron_type_lst=None) -> pd.core.groupby.DataFrameGroupBy:\n",
    "        \"\"\"Process subspace data with string replacements and filtering.\"\"\"\n",
    "        # Create a copy to avoid SettingWithCopyWarning\n",
    "        df = data.copy()\n",
    "        # Replace neuron type strings\n",
    "        df[\"neuron\"] = df[\"neuron\"].str.replace(\"sampled_common\", \"random\", regex=False)\n",
    "        df[\"neuron\"] = df[\"neuron\"].str.replace(\"common\", \"all\", regex=False)\n",
    "        # Filter by neuron type if list provided\n",
    "        if neuron_type_lst:\n",
    "            df = df[~df[\"neuron\"].isin(neuron_type_lst)]\n",
    "        # Calculate dimension proportion\n",
    "        df[\"dim_prop\"] = df[\"effective_dim\"] / df[\"total_dim\"]\n",
    "        return df.groupby(\"neuron\")\n",
    "\n",
    "    def load_orthogonality(\n",
    "        self, data: pd.DataFrame, neuron_type_lst = None\n",
    "    ) -> pd.core.groupby.DataFrameGroupBy:\n",
    "        \"\"\"Process orthogonality data with string replacements and filtering.\"\"\"\n",
    "        # Create a copy to avoid SettingWithCopyWarning\n",
    "        df = data.copy()\n",
    "        # Replace pair strings (order matters - replace longer pattern first)\n",
    "        df[\"pair\"] = df[\"pair\"].str.replace(\"sampled_common\", \"random\", regex=False)\n",
    "        df[\"pair\"] = df[\"pair\"].str.replace(\"common\", \"all\", regex=False)\n",
    "        # Filter by neuron type if list provided\n",
    "        if neuron_type_lst:\n",
    "            # Exclude pairs containing any item from neuron_type_lst\n",
    "            df = df[~df[\"pair\"].apply(lambda pair: any(item in pair for item in neuron_type_lst))]\n",
    "        return df.groupby(\"pair\")\n",
    "\n",
    "    def load_file(self, file_path: Path, metric: str, neuron_type_lst = None) :\n",
    "        \"\"\"Main function to load and process metric data files.\"\"\"\n",
    "        # Load data with log step conversion\n",
    "        data = self.convert_log_step(file_path)\n",
    "        # Route to appropriate processing function based on metric\n",
    "        if metric == \"subspace\":\n",
    "            return self.load_subspace(data, neuron_type_lst=neuron_type_lst)\n",
    "        if metric == \"orthogonality\":\n",
    "            return self.load_orthogonality(data, neuron_type_lst=neuron_type_lst)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_geometry_step(geometry_path,output_path, metric, model_lst, neuron_lst, neuron_type_lst, ylim_dict, metric_dict):\n",
    "    for model in model_lst:\n",
    "        for neuron in neuron_lst:\n",
    "            file_path = geometry_path / f\"pythia-{model}-deduped\" / metric / f\"500_{neuron}.csv\"\n",
    "            geometry_loader = GeometryLoader()\n",
    "            data_grouped = geometry_loader.load_file(file_path, metric=metric, neuron_type_lst=neuron_type_lst)\n",
    "            for metric_val in metric_dict[metric]:\n",
    "                for neuron_type, data_group in data_grouped:\n",
    "                    plt.grid(alpha=0.2)\n",
    "                    plt.plot(data_group[\"log_step\"], data_group[metric_val], label=neuron_type)\n",
    "                    plt.title(f\"{metric_val}: #neuron={neuron}, model={model}\")\n",
    "                plt.ylim(ylim_dict[metric_val])\n",
    "                plt.xlabel(\"Log step\", fontsize=12)\n",
    "                plt.ylabel(metric_val, fontsize=12)\n",
    "                plt.legend()\n",
    "                output_file = output_path / metric_val / f\"{model}_{neuron}.png\"\n",
    "                output_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "                plt.savefig(output_file, dpi=300, bbox_inches=\"tight\")\n",
    "                plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load file\n",
    "model_lst = [\"70m\", \"410m\"]\n",
    "#metric_lst = [\"subspace\"]\n",
    "metric_lst = [\"orthogonality\"]\n",
    "neuron_lst = [10, 50, 500]\n",
    "metric_dict = {\n",
    "    \"subspace\": [\"dim_prop\", \"sv_decay_rate_2\"],\n",
    "    \"orthogonality\": [\"full_mean_angle_degrees\", \"principal_mean_angle_degrees\"],\n",
    "}\n",
    "ylim_dict = {\n",
    "    \"dim_prop\": [0, 1.1],\n",
    "    \"sv_decay_rate_2\": [1, 3],\n",
    "    \"full_mean_angle_degrees\": [85, 95],\n",
    "    \"principal_mean_angle_degrees\": [5, 120],\n",
    "}\n",
    "\n",
    "\n",
    "neuron_type_lst = [\"all-\",\"random_2-\"]\n",
    "\n",
    "for metric in metric_lst:\n",
    "    output_path = fig_path / metric\n",
    "    plot_geometry_step(geometry_path,output_path, metric, model_lst, neuron_lst, neuron_type_lst, ylim_dict, metric_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuron",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
